/**
 * WhisperEngine.kt - Main orchestrator for SOLID Whisper engine
 * 
 * Copyright (C) Augmentalis Inc, Intelligent Devices LLC
 * Author: Manoj Jhawar
 * Created: 2025-09-03
 * 
 * Refactored Whisper engine using SOLID principles with 6 focused components.
 * This is the main orchestrator that coordinates all specialized components.
 * 
 * COMPONENTS:
 * - WhisperModel: Model management and loading
 * - WhisperNative: Native library integration
 * - WhisperProcessor: Audio processing and VAD
 * - WhisperConfig: Configuration management
 * - WhisperErrorHandler: Error handling and recovery
 * - Shared components: PerformanceMonitor, AudioStateManager, ServiceState, ResultProcessor
 */
package com.augmentalis.voiceos.speech.engines.whisper

import android.content.Context
import android.util.Log
import com.augmentalis.speechrecognition.SpeechConfig
import com.augmentalis.speechrecognition.SpeechMode
import com.augmentalis.voiceos.speech.api.OnSpeechErrorListener
import com.augmentalis.voiceos.speech.api.OnSpeechResultListener
import com.augmentalis.voiceos.speech.api.RecognitionResult
import com.augmentalis.voiceos.speech.api.WordTimestamp
import com.augmentalis.voiceos.speech.engines.common.*
// import com.augmentalis.datamanager.repositories.RecognitionLearningRepository
// import com.augmentalis.datamanager.entities.EngineType
import com.augmentalis.voiceos.speech.engines.whisper.*
import kotlinx.coroutines.*
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.sync.Mutex
import kotlinx.coroutines.sync.withLock
import java.util.*
import java.util.concurrent.ConcurrentHashMap
import kotlin.collections.ArrayList

/**
 * SOLID-principles Whisper speech recognition engine.
 * Orchestrates 6 specialized components for better maintainability, testability, and extensibility.
 * 
 * Component Architecture:
 * - WhisperModel: Handles model loading, validation, and lifecycle
 * - WhisperNative: Manages native library integration and inference
 * - WhisperProcessor: Processes audio streams, VAD, and noise reduction
 * - WhisperConfig: Centralized configuration management and persistence
 * - WhisperErrorHandler: Comprehensive error handling and recovery
 * - Shared Components: Performance, audio state, service state, result processing
 */
class WhisperEngine(
    private val context: Context
) {
    
    companion object {
        private const val TAG = "WhisperEngine"
    }
    
    // ===== COMPONENT DEPENDENCIES =====
    // Shared components (dependency injection)
    private val serviceState = ServiceState()
    private val audioStateManager = AudioStateManager("Whisper")
    private val performanceMonitor = PerformanceMonitor("Whisper")
    private val resultProcessor = ResultProcessor()
    private val errorRecoveryManager = ErrorRecoveryManager("Whisper", context)
    
    // Whisper-specific components
    private lateinit var whisperConfig: WhisperConfig
    private lateinit var whisperModel: WhisperModel
    private lateinit var whisperNative: WhisperNative
    private lateinit var whisperProcessor: WhisperProcessor
    private lateinit var whisperErrorHandler: WhisperErrorHandler
    
    // ===== ENGINE STATE =====
    private val voiceStateManager = VoiceStateManager(context, "Whisper")
    @Volatile private var isListening = false
    
    // Coroutines and synchronization
    private val engineScope = CoroutineScope(Dispatchers.Main + SupervisorJob())
    private val engineMutex = Mutex()
    
    // Learning system
    private val registeredCommands = Collections.synchronizedList(arrayListOf<String>())
    private val learnedCommands = ConcurrentHashMap<String, String>()
    private val vocabularyCache = ConcurrentHashMap<String, Boolean>()
    private val commandCache = CommandCache()
    private lateinit var learningRepository: RecognitionLearningRepository
    
    // Listeners
    private var resultListener: OnSpeechResultListener? = null
    private var partialResultListener: ((String) -> Unit)? = null
    private var errorListener: OnSpeechErrorListener? = null
    
    // Result flow
    private val _resultFlow = MutableStateFlow<RecognitionResult?>(null)
    val resultFlow: StateFlow<RecognitionResult?> = _resultFlow
    
    // Engine configuration
    private lateinit var speechConfig: SpeechConfig
    private lateinit var currentWhisperConfig: WhisperEngineConfig
    
    // Advanced features state
    private var detectedLanguage: String = ""
    private var currentSegmentStartTime = 0L
    private val wordTimestamps = mutableListOf<WordTimestamp>()
    
    // Timeout management
    private val timeoutManager = TimeoutManager(engineScope)
    
    /**
     * Initialize the engine with UniversalInitializationManager protection
     * CRITICAL FIX: Thread-safe initialization with retry logic and race condition prevention
     */
    suspend fun initialize(config: SpeechConfig): Boolean {
        Log.i(TAG, "Starting WhisperEngine initialization with universal protection")
        
        val initConfig = UniversalInitializationManager.InitializationConfig(
            engineName = "WhisperEngine",
            maxRetries = 3,
            initialDelayMs = 1000L,
            maxDelayMs = 8000L,
            backoffMultiplier = 2.0,
            jitterMs = 500L,
            timeoutMs = 30000L,
            allowDegradedMode = false // Whisper doesn't have degraded mode
        )
        
        val result = UniversalInitializationManager.instance.initializeEngine(
            config = initConfig,
            context = context
        ) { ctx ->
            performActualInitialization(ctx, config)
        }
        
        return when {
            result.success && result.state == UniversalInitializationManager.InitializationState.INITIALIZED -> {
                Log.i(TAG, "WhisperEngine initialized successfully in ${result.totalDuration}ms")
                true
            }
            else -> {
                Log.e(TAG, "WhisperEngine initialization failed: ${result.error}")
                false
            }
        }
    }
    
    /**
     * Perform actual initialization with proper error handling (thread-safe, single execution)
     */
    @Suppress("UNUSED_PARAMETER")
    private suspend fun performActualInitialization(context: Context, config: SpeechConfig): Boolean = engineMutex.withLock {
        if (voiceStateManager.isInitialized()) {
            Log.d(TAG, "Engine already initialized")
            return true
        }
        
        return try {
            val startTime = System.currentTimeMillis()
            serviceState.setState(ServiceState.State.INITIALIZING)
            this.speechConfig = config
            
            Log.i(TAG, "ðŸš€ Performing actual SOLID Whisper engine initialization...")
            
            // Initialize shared components first
            initializeSharedComponents()
            
            // Initialize Whisper-specific components
            val success = initializeWhisperComponents()
            
            if (success) {
                // Initialize learning system
                initializeLearningSystem()
                
                // Set up component callbacks and wiring
                wireComponents()
                
                // Final state setup
                voiceStateManager.initialize()
                voiceStateManager.setVoiceEnabled(config.voiceEnabled)
                voiceStateManager.updateCommandExecutionTime()
                
                serviceState.setState(ServiceState.State.READY)
                
                val duration = System.currentTimeMillis() - startTime
                performanceMonitor.recordSlowOperation("initialization", duration, 10000L)
                
                if (voiceStateManager.isVoiceEnabled()) {
                    startTimeoutMonitoring()
                }
                
                Log.i(TAG, "âœ… SOLID Whisper engine initialized successfully in ${duration}ms")
                true
            } else {
                serviceState.setState(ServiceState.State.ERROR, "Component initialization failed")
                false
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "Failed to initialize SOLID Whisper engine", e)
            whisperErrorHandler.handleError(
                WhisperErrorCode.INITIALIZATION_ERROR,
                "Engine initialization failed: ${e.message}",
                e
            )
            serviceState.setState(ServiceState.State.ERROR, e.message)
            false
        }
    }
    
    /**
     * Initialize shared components
     */
    private fun initializeSharedComponents() {
        // Configure result processor
        resultProcessor.setMode(speechConfig.mode)
        resultProcessor.setConfidenceThreshold(speechConfig.confidenceThreshold)
        
        // Start performance monitoring
        performanceMonitor.startSession()
        
        Log.d(TAG, "âœ… Shared components initialized")
    }
    
    /**
     * Initialize Whisper-specific components
     */
    private suspend fun initializeWhisperComponents(): Boolean {
        return try {
            // Initialize error handler first
            whisperErrorHandler = WhisperErrorHandler(context, errorRecoveryManager, performanceMonitor)
            
            // Initialize configuration management
            whisperConfig = WhisperConfig(context)
            currentWhisperConfig = whisperConfig.createFromSpeechConfig(speechConfig)
            
            // Apply device optimizations
            whisperConfig.applyDeviceOptimizations()
            currentWhisperConfig = whisperConfig.getCurrentConfig()
            
            // Initialize model management
            whisperModel = WhisperModel(context, performanceMonitor)
            val modelInitialized = whisperModel.initialize()
            if (!modelInitialized) {
                throw Exception("WhisperModel initialization failed")
            }
            
            // Initialize native integration
            whisperNative = WhisperNative(context, performanceMonitor)
            val nativeInitialized = whisperNative.initialize()
            if (!nativeInitialized) {
                throw Exception("WhisperNative initialization failed")
            }
            
            // Initialize audio processor
            whisperProcessor = WhisperProcessor(audioStateManager, performanceMonitor)
            val processorInitialized = whisperProcessor.initialize()
            if (!processorInitialized) {
                throw Exception("WhisperProcessor initialization failed")
            }
            
            // Load initial model
            val modelLoaded = whisperModel.loadModel(currentWhisperConfig.modelSize)
            if (!modelLoaded) {
                throw Exception("Initial model loading failed")
            }
            
            Log.d(TAG, "âœ… Whisper components initialized")
            true
            
        } catch (e: Exception) {
            Log.e(TAG, "Whisper component initialization failed", e)
            false
        }
    }
    
    /**
     * Initialize learning system integration
     */
    private suspend fun initializeLearningSystem() {
        try {
            Log.i(TAG, "ðŸ§  Initializing Room learning system...")
            learningRepository = RecognitionLearningRepository.getInstance(context)
            learningRepository.initialize()
            loadLearnedCommands()
            loadVocabularyCache()
            Log.d(TAG, "âœ… Learning system initialized")
        } catch (e: Exception) {
            Log.e(TAG, "Learning system initialization failed", e)
        }
    }
    
    /**
     * Wire components together with callbacks and event handling
     */
    private fun wireComponents() {
        // Error handler callbacks
        whisperErrorHandler.setErrorListener { message, code ->
            errorListener?.invoke(message, code)
        }
        
        whisperErrorHandler.setCriticalErrorCallback { error ->
            Log.e(TAG, "CRITICAL ERROR: ${error.message}")
            // Could trigger engine restart or notify user
        }
        
        // Model callbacks
        whisperModel.setOnModelLoaded { modelSize, path ->
            Log.i(TAG, "Model loaded: ${modelSize.modelName} at $path")
            // Update native with new model
            engineScope.launch {
                whisperNative.loadModel(path)
            }
        }
        
        whisperModel.setOnModelError { message, exception ->
            engineScope.launch {
                whisperErrorHandler.handleError(
                    WhisperErrorCode.MODEL_LOAD_ERROR,
                    message,
                    exception
                )
            }
        }
        
        // Audio processor callbacks
        whisperProcessor.setCallbacks(
            onReady = { audioData ->
                // Audio is ready for inference
                engineScope.launch {
                    processAudioWithInference(audioData)
                }
            },
            onVadChanged = { hasSpeech ->
                Log.d(TAG, "VAD state changed: ${if (hasSpeech) "SPEECH" else "SILENCE"}")
            },
            onError = { message, exception ->
                engineScope.launch {
                    whisperErrorHandler.handleError(
                        WhisperErrorCode.AUDIO_PROCESSING_ERROR,
                        message,
                        exception
                    )
                }
            }
        )
        
        // Native inference callbacks
        whisperNative.setCallbacks(
            onStarted = {
                serviceState.setState(ServiceState.State.PROCESSING)
            },
            onCompleted = { result ->
                engineScope.launch {
                    handleWhisperResult(result)
                }
            },
            onError = { message, exception ->
                engineScope.launch {
                    whisperErrorHandler.handleError(
                        WhisperErrorCode.INFERENCE_ERROR,
                        message,
                        exception
                    )
                }
            }
        )
        
        // Configuration change callbacks
        whisperConfig.addChangeListener { oldConfig, newConfig ->
            engineScope.launch {
                applyConfigurationChanges(oldConfig, newConfig)
            }
        }
        
        Log.d(TAG, "âœ… Components wired together")
    }
    
    /**
     * Process audio data through native inference
     */
    private suspend fun processAudioWithInference(audioData: FloatArray) {
        if (!whisperNative.isInferenceInProgress()) {
            val params = WhisperInferenceParams(
                temperature = currentWhisperConfig.temperature,
                beamSize = currentWhisperConfig.beamSize,
                bestOf = currentWhisperConfig.bestOf,
                enableWordTimestamps = currentWhisperConfig.enableWordTimestamps,
                enableLanguageDetection = currentWhisperConfig.enableLanguageDetection,
                enableTranslation = currentWhisperConfig.enableTranslation,
                targetLanguage = currentWhisperConfig.targetTranslationLanguage
            )
            
            whisperNative.runInference(audioData, params)
        }
    }
    
    /**
     * Handle Whisper recognition result
     */
    private suspend fun handleWhisperResult(whisperResult: WhisperResult) {
        val text = whisperResult.text.trim()
        if (text.isEmpty()) return
        
        Log.d(TAG, "Whisper result: '$text' (confidence: ${whisperResult.confidence})")
        
        // Update detected language
        if (currentWhisperConfig.enableLanguageDetection) {
            detectedLanguage = whisperResult.language
        }
        
        // Store word timestamps
        if (currentWhisperConfig.enableWordTimestamps) {
            wordTimestamps.clear()
            whisperResult.segments.forEach { segment ->
                wordTimestamps.addAll(segment.words)
            }
        }
        
        // Apply confidence threshold
        if (whisperResult.confidence < currentWhisperConfig.confidenceThreshold) {
            Log.d(TAG, "Recognition confidence too low: ${whisperResult.confidence} < ${currentWhisperConfig.confidenceThreshold}")
            partialResultListener?.invoke(text)
            return
        }
        
        // Handle different modes
        if (voiceStateManager.isDictationActive()) {
            handleDictationResult(text, whisperResult)
        } else {
            handleCommandResult(text, whisperResult)
        }
        
        serviceState.setState(ServiceState.State.LISTENING)
    }
    
    /**
     * Handle dictation mode result
     */
    private suspend fun handleDictationResult(text: String, whisperResult: WhisperResult) {
        // Check for stop dictation command
        if (text.equals(speechConfig.stopDictationCommand, ignoreCase = true)) {
            voiceStateManager.exitDictationMode()
            serviceState.setState(ServiceState.State.LISTENING)
            resultProcessor.setMode(SpeechMode.DYNAMIC_COMMAND)
            Log.d(TAG, "Dictation stopped by command")
            return
        }
        
        // Process result through result processor
        val result = resultProcessor.createResult(
            text = text,
            confidence = whisperResult.confidence,
            engine = "whisper"
        ).copy(
            language = whisperResult.language,
            translation = whisperResult.translation,
            wordTimestamps = if (currentWhisperConfig.enableWordTimestamps) wordTimestamps.toList() else null
        )
        
        resultListener?.invoke(result)
        _resultFlow.value = result
        
        Log.d(TAG, "âœ… Dictation result sent: '$text'")
    }
    
    /**
     * Handle command mode result
     */
    private suspend fun handleCommandResult(text: String, whisperResult: WhisperResult) {
        // Check for voice commands
        when {
            voiceStateManager.isVoiceEnabled() && text.equals(speechConfig.muteCommand, ignoreCase = true) -> {
                handleMuteCommand()
                return
            }
            
            checkUnmuteCommand(text) -> {
                handleUnmuteCommand()
                return
            }
            
            text.equals(speechConfig.startDictationCommand, ignoreCase = true) -> {
                startDictationMode()
                return
            }
        }
        
        // Process command with learning system
        val (matchedCommand, wasLearned) = processCommandWithLearning(text)
        val finalCommand = matchedCommand ?: text
        
        // Create result
        val result = resultProcessor.createResult(
            text = finalCommand,
            confidence = whisperResult.confidence,
            engine = "whisper"
        ).copy(
            language = whisperResult.language,
            translation = whisperResult.translation,
            wordTimestamps = if (currentWhisperConfig.enableWordTimestamps) wordTimestamps.toList() else null
        )
        
        // Log learning activity
        if (wasLearned && matchedCommand != null) {
            Log.i(TAG, "ðŸ§  Enhanced command via learning: '$text' â†’ '$matchedCommand'")
        }
        
        resultListener?.invoke(result)
        _resultFlow.value = result
        
        // Update command execution time
        voiceStateManager.updateCommandExecutionTime()
        
        Log.d(TAG, "âœ… Command result sent: '$finalCommand'")
    }
    
    /**
     * Apply configuration changes to components
     */
    private suspend fun applyConfigurationChanges(oldConfig: WhisperEngineConfig, newConfig: WhisperEngineConfig) {
        try {
            // Update audio processor settings
            whisperProcessor.setProcessingMode(newConfig.processingMode)
            whisperProcessor.setNoiseReductionLevel(newConfig.noiseReductionLevel)
            whisperProcessor.setVadSensitivity(newConfig.vadSensitivity)
            
            // Update native inference parameters
            whisperNative.setInferenceParams(
                WhisperInferenceParams(
                    temperature = newConfig.temperature,
                    beamSize = newConfig.beamSize,
                    bestOf = newConfig.bestOf,
                    enableWordTimestamps = newConfig.enableWordTimestamps,
                    enableLanguageDetection = newConfig.enableLanguageDetection,
                    enableTranslation = newConfig.enableTranslation,
                    targetLanguage = newConfig.targetTranslationLanguage
                )
            )
            
            // Change model if needed
            if (oldConfig.modelSize != newConfig.modelSize) {
                Log.i(TAG, "Model size changed: ${oldConfig.modelSize} â†’ ${newConfig.modelSize}")
                whisperModel.changeModel(newConfig.modelSize)
            }
            
            currentWhisperConfig = newConfig
            Log.d(TAG, "âœ… Configuration changes applied")
            
        } catch (e: Exception) {
            Log.e(TAG, "Error applying configuration changes", e)
            whisperErrorHandler.handleError(
                WhisperErrorCode.CONFIGURATION_ERROR,
                "Failed to apply configuration changes: ${e.message}",
                e
            )
        }
    }
    
    /**
     * Start listening for speech
     */
    fun startListening() {
        if (!voiceStateManager.isInitialized()) {
            Log.e(TAG, "Engine not initialized")
            return
        }
        
        engineScope.launch {
            engineMutex.withLock {
                if (isListening) {
                    Log.d(TAG, "Already listening")
                    return@withLock
                }
                
                isListening = true
                serviceState.setState(ServiceState.State.LISTENING)
                
                // Start audio processing
                val success = whisperProcessor.startProcessing()
                
                if (success) {
                    // Reset timeout
                    voiceStateManager.updateCommandExecutionTime()
                    if (voiceStateManager.isVoiceEnabled() && !voiceStateManager.isVoiceSleeping()) {
                        startTimeoutMonitoring()
                    }
                    
                    Log.d(TAG, "âœ… Started listening with SOLID Whisper engine")
                } else {
                    isListening = false
                    serviceState.setState(ServiceState.State.ERROR, "Failed to start audio processing")
                }
            }
        }
    }
    
    /**
     * Stop listening for speech
     */
    fun stopListening() {
        engineScope.launch {
            engineMutex.withLock {
                if (!isListening) {
                    return@withLock
                }
                
                isListening = false
                voiceStateManager.exitDictationMode()
                
                // Stop audio processing
                whisperProcessor.stopProcessing()
                
                serviceState.setState(ServiceState.State.READY)
                
                Log.d(TAG, "âœ… Stopped listening")
            }
        }
    }
    
    // ===== VOICE CONTROL METHODS =====
    
    private fun startDictationMode() {
        voiceStateManager.enterDictationMode()
        serviceState.setState(ServiceState.State.FREE_SPEECH)
        resultProcessor.setMode(SpeechMode.DICTATION)
        Log.d(TAG, "âœ… Dictation mode activated")
    }
    
    private fun handleMuteCommand() {
        voiceStateManager.enterSleepMode()
        serviceState.setState(ServiceState.State.SLEEPING)
        Log.d(TAG, "âœ… Voice muted")
    }
    
    private fun handleUnmuteCommand() {
        voiceStateManager.exitSleepMode()
        serviceState.setState(ServiceState.State.READY)
        if (voiceStateManager.isVoiceEnabled()) {
            startTimeoutMonitoring()
        }
        Log.d(TAG, "âœ… Voice unmuted")
    }
    
    private fun checkUnmuteCommand(command: String): Boolean {
        return voiceStateManager.isVoiceSleeping() && command.equals(speechConfig.unmuteCommand, ignoreCase = true)
    }
    
    private fun startTimeoutMonitoring() {
        engineScope.launch {
            while (voiceStateManager.isVoiceEnabled() && !voiceStateManager.isVoiceSleeping()) {
                delay(30000) // Check every 30 seconds
                
                if (voiceStateManager.shouldTimeout(speechConfig.voiceTimeoutMinutes.toInt())) {
                    voiceStateManager.enterSleepMode()
                    serviceState.setState(ServiceState.State.SLEEPING)
                    Log.d(TAG, "âœ… Voice timeout reached - entering sleep mode")
                    break
                }
            }
        }
    }
    
    // ===== LEARNING SYSTEM =====
    
    private suspend fun loadLearnedCommands() {
        try {
            val loadedCommands = learningRepository.getLearnedCommands(EngineType.WHISPER)
            learnedCommands.clear()
            learnedCommands.putAll(loadedCommands)
            Log.i(TAG, "ðŸ§  Loaded ${learnedCommands.size} learned commands")
        } catch (e: Exception) {
            Log.e(TAG, "ðŸ§  Failed to load learned commands: ${e.message}")
        }
    }
    
    private suspend fun loadVocabularyCache() {
        try {
            val loadedCache = learningRepository.getVocabularyCache(EngineType.WHISPER)
            vocabularyCache.clear()
            vocabularyCache.putAll(loadedCache)
            Log.i(TAG, "ðŸ§  Loaded ${vocabularyCache.size} vocabulary cache entries")
        } catch (e: Exception) {
            Log.e(TAG, "ðŸ§  Failed to load vocabulary cache: ${e.message}")
        }
    }
    
    private fun saveLearnedCommand(recognized: String, matched: String) {
        learnedCommands[recognized] = matched
        Log.d(TAG, "ðŸ§  Learning: '$recognized' â†’ '$matched'")
        
        engineScope.launch(Dispatchers.IO) {
            try {
                learningRepository.saveLearnedCommand(EngineType.WHISPER, recognized, matched)
            } catch (e: Exception) {
                Log.e(TAG, "ðŸ§  Failed to save learned command: ${e.message}")
            }
        }
    }
    
    private suspend fun processCommandWithLearning(command: String): Pair<String?, Boolean> {
        var matchedCommand: String? = null
        var isSuccess = false
        
        // Tier 1: Check learned commands first
        if (learnedCommands.containsKey(command)) {
            matchedCommand = learnedCommands[command]
            isSuccess = true
        }
        // Tier 2: Use shared CommandCache for similarity matching
        else {
            val match = commandCache.findMatch(command)
            if (match != null) {
                matchedCommand = match
                isSuccess = true
                // Auto-learn successful similarity matches
                saveLearnedCommand(command, match)
            }
        }
        
        return Pair(matchedCommand, isSuccess)
    }
    
    // ===== INTERFACE METHODS =====
    
    fun setDynamicCommands(commands: List<String>) {
        registeredCommands.clear()
        registeredCommands.addAll(commands)
        
        engineScope.launch {
            commandCache.updateCommands(commands)
            Log.d(TAG, "ðŸ§  Registered ${commands.size} commands for learning system")
        }
    }
    
    fun setResultListener(listener: OnSpeechResultListener) {
        this.resultListener = listener
    }
    
    fun setPartialResultListener(listener: (String) -> Unit) {
        this.partialResultListener = listener
    }
    
    fun setErrorListener(listener: OnSpeechErrorListener) {
        this.errorListener = listener
    }
    
    // ===== ADVANCED WHISPER FEATURES =====
    
    fun getDetectedLanguage(): String = detectedLanguage
    
    fun getWordTimestamps(): List<WordTimestamp> = wordTimestamps.toList()
    
    suspend fun changeModel(modelSize: WhisperModelSize): Boolean {
        return whisperModel.changeModel(modelSize)
    }
    
    fun setTranslationEnabled(enabled: Boolean, targetLanguage: String = "en") {
        engineScope.launch {
            val newConfig = currentWhisperConfig.copy(
                enableTranslation = enabled,
                targetTranslationLanguage = targetLanguage
            )
            whisperConfig.updateConfig(newConfig)
        }
    }
    
    fun setNoiseReductionLevel(level: Float) {
        whisperProcessor.setNoiseReductionLevel(level)
    }
    
    fun getProcessingStats(): Map<String, Any> {
        return mapOf(
            "modelStats" to whisperModel.getModelStats(),
            "nativeInfo" to whisperNative.getNativeInfo(),
            "processingStats" to whisperProcessor.getProcessingStats(),
            "configStats" to whisperConfig.getConfigMap(),
            "errorStats" to whisperErrorHandler.getErrorStatistics(),
            "performanceStats" to performanceMonitor.getMetrics(),
            "serviceState" to serviceState.currentState.name
        )
    }
    
    /**
     * Destroy the engine and release all resources
     */
    suspend fun destroy() {
        try {
            Log.d(TAG, "Destroying SOLID Whisper engine...")
            
            // Stop all operations
            stopListening()
            
            // Destroy components in reverse order
            whisperProcessor.destroy()
            whisperNative.destroy()
            whisperModel.destroy()
            whisperErrorHandler.destroy()
            
            // Clean up shared components
            performanceMonitor.destroy()
            voiceStateManager.destroy()
            
            // Cancel coroutines
            engineScope.cancel()
            
            // Close learning repository
            if (::learningRepository.isInitialized) {
                // Room handles connection management automatically
            }
            
            // Clear caches
            registeredCommands.clear()
            learnedCommands.clear()
            vocabularyCache.clear()
            wordTimestamps.clear()
            
            // Reset state
            isListening = false
            voiceStateManager.reset()
            
            serviceState.setState(ServiceState.State.SHUTDOWN)
            
            Log.i(TAG, "âœ… SOLID Whisper engine destroyed")
            
        } catch (e: Exception) {
            Log.e(TAG, "Error during SOLID engine destroy", e)
        }
    }
}
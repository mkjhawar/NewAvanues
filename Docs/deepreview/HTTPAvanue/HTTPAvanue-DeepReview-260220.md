# HTTPAvanue Module — Deep Code Review
**Date:** 260220
**Scope:** `Modules/HTTPAvanue/src/` — 68 .kt files
**Branch:** HTTPAvanue
**Reviewer:** Code-Reviewer Agent (sonnet)

---

## Summary

HTTPAvanue is a solid, well-structured KMP HTTP server/client library. The core HTTP/1.1 server, WebSocket handshake, flow-control arithmetic, and client-side connection pooling are functionally correct. However, three issues are production-blocking: concurrent HTTP/2 streams sharing a single unsynchronized Okio sink will corrupt framing under any multi-stream load; the HPACK Huffman decoder is not implemented (the isHuffman flag is silently ignored, decoding compressed header bytes as raw UTF-8); and StaticFileMiddleware has no path traversal guard. Several medium and low issues round out the report.

---

## Issues

| Severity | File:Line | Issue | Suggestion |
|----------|-----------|-------|------------|
| **Critical** | `http2/Http2Connection.kt:122,131,230` | **HTTP/2 sink not synchronized — frame corruption under concurrent streams.** `dispatchRequest()` is launched as a new coroutine via `scope.launch { dispatchRequest(sink, stream) }` for every incoming HEADERS frame (L122) and CONTINUATION frame (L131). `sendResponse()` (L211) calls `Http2FrameCodec.writeHeaders` and `Http2FrameCodec.writeData` — each of which calls `writeFrame()` → `sink.flush()`. The `sink` is the same `BufferedSink` for the entire connection, shared across all coroutines without a `Mutex`. Two concurrent streams interleave their writes, producing garbled frames that break the entire HTTP/2 session. Confirmed: `Http2FrameCodec.writeFrame()` is NOT synchronized. | Add a `private val sinkMutex = Mutex()` to `Http2Connection`. Wrap all `Http2FrameCodec.write*()` calls inside `sinkMutex.withLock { }` — both in `sendResponse()` and in the error paths in `dispatchRequest()`. Pattern: `sinkMutex.withLock { Http2FrameCodec.writeHeaders(sink, ...) }`. |
| **Critical** | `hpack/HpackDecoder.kt:108-114` | **Huffman decoding not implemented — both branches decode bytes identically as raw UTF-8.** In `decodeString()`, the `isHuffman` flag is read (L104) but then the `if (isHuffman)` and `else` branches (L108-114) both call `stringBytes.decodeToString()`. Huffman-compressed header values, which browsers send by default, are decoded as the raw Huffman-coded bytes rather than the decompressed string, producing garbage values for all headers. Any browser sending `hpack_header_table_size` in SETTINGS will trigger Huffman encoding. This means HTTP/2 is entirely non-functional against real browsers. Note: the comment at L109 reads "Huffman decoding deferred — for now, treat as raw bytes" — this is a Rule 1 stub. | Implement the RFC 7541 Appendix B Huffman decoder. The static code table is ~256-entry, well-known, and compact. A canonical implementation that walks the Huffman tree bit-by-bit is approximately 30 lines. Alternatively, embed the standard 256-entry decode table as a `ByteArray` constant and implement a fast decode loop. Until this is done, HTTP/2 interop with any compliant client (curl, browsers, Retrofit) is broken for compressed headers. |
| **Critical** | `middleware/StaticFileMiddleware.kt:14` | **Path traversal vulnerability — no `..` check before serving files.** `filePath` is derived directly from `request.path.removePrefix(urlPrefix).trimStart('/')`. There is no check for `..` sequences. A request such as `GET /static/../../etc/passwd` will resolve to `../../etc/passwd` which `readResource()` may serve depending on platform implementation. All three platform `readResource` actuals ultimately resolve relative to the process working directory or resource root. On Android, `Resources.android.kt` uses `context.assets.open(path)` — assets are read-only, so traversal is harmless there. On Desktop, `Resources.desktop.kt` reads from the JAR classpath, also limited. On iOS, `Resources.ios.kt` uses `NSBundle.mainBundle.pathForResource` — also bounded. However, the middleware is the wrong place to rely on platform containment; the correct fix is at the middleware layer. | Before composing `fullPath`, validate that the normalized result does not escape the root: `val normalized = filePath.replace("\\", "/").split("/").filter { it != ".." && it != "." }.joinToString("/")`. Then check `normalized != filePath` (after normalization). Reject with `403 Forbidden` if any `..` segment is present. |
| **High** | `http2/Http2Connection.kt:93` | **SETTINGS ACK sends a fresh default SETTINGS frame body instead of an empty payload.** `Http2FrameCodec.writeSettings(sink, Http2Settings(), ack = true)` — when `ack = true`, the codec correctly sends an empty payload (`Http2Settings()` is discarded because `payload = if (ack) byteArrayOf() else Http2Settings.encode(settings)`). This is correct at the codec level. However, constructing `Http2Settings()` still allocates an object for no reason. More importantly, the local `handleSettings()` never updates `hpackEncoder` when `remoteSettings.headerTableSize` changes (L90: `remoteSettings = Http2Settings.decode(frame.payload)` but the encoder is initialized at construction with `remoteSettings.headerTableSize` — L23 — and never re-synced). The encoder's dynamic table remains sized at the initial value forever. | After `remoteSettings = Http2Settings.decode(frame.payload)`, call `hpackEncoder.dynamicTable.setMaxSize(remoteSettings.headerTableSize)` to keep the encoder's table in sync with peer acknowledgments. (Expose `dynamicTable` or add a `setMaxDynamicTableSize()` method on `HpackEncoder`.) |
| **High** | `http2/Http2Connection.kt:226-232` | **Response DATA frames sent without checking the send flow control window.** `sendResponse()` chunks the body and calls `Http2FrameCodec.writeData()` for each chunk. It uses `remoteSettings.maxFrameSize` as the chunk size, but does NOT consult `flowControl.availableSendBytes()` or `stream.sendWindowSize` before writing. If the peer's flow control window is smaller than the chunk, the server sends frames the receiver is not ready to accept, which is an RFC 7540 Section 6.9 violation. The peer should send RST_STREAM or GOAWAY. | Before each DATA frame write, check `flowControl.availableSendBytes(stream, chunkSize)` and block (using a `Channel` or a `Mutex`-guarded loop) until the window is sufficient. This requires restructuring `sendResponse()` to be a `suspend fun` (it currently is not) and waiting for WINDOW_UPDATE frames from the peer. |
| **High** | `sse/SseEmitter.kt:72` | **SseConnectionManager is not thread-safe — `emitters` mutableMap accessed from multiple coroutines.** `createEmitter()`, `removeEmitter()`, `broadcast()`, `getEmitter()`, and `activeCount` all access the same `private val emitters = mutableMapOf<String, SseEmitter>()` without any synchronization. `broadcast()` is a `suspend fun` called from one coroutine; `createEmitter()` and `removeEmitter()` may be called from other coroutines (e.g., HTTP route handlers). Concurrent read/write to a plain `MutableMap` is a data race. | Add `private val mutex = Mutex()` and wrap all map accesses with `mutex.withLock { }`. For `broadcast()`, take a snapshot of the map inside the lock and then iterate/send outside it: `val snapshot = mutex.withLock { emitters.toMap() }`. |
| **High** | `server/HttpServer.kt:69-71` | **`activeConnections` mutableSetOf accessed from multiple coroutines without synchronization.** `activeConnections` is a `mutableSetOf<Job>()` modified from the `serverJob` coroutine (add, invokeOnCompletion/remove). `invokeOnCompletion` fires on an arbitrary thread (whichever completed the job). Both `add()` and `remove()` can race. `stop()` also reads and clears `activeConnections` from a different scope. | Replace with a `ConcurrentHashMap<Job, Unit>` or guard with a `Mutex` and `withLock`. |
| **High** | `server/HttpServer.kt:63` | **`serverJob` created in `CoroutineScope(Dispatchers.Default).launch` — unscoped, leaked on stop failure.** The coroutine scope is anonymous and not tracked. If `stop()` is never called, the server loop runs forever. More critically, if `start()` is called multiple times (guard at L56-59 is check-then-act, not atomic), two server jobs can run simultaneously. | Use a structured `CoroutineScope` stored as a field: `private val serverScope = CoroutineScope(Dispatchers.Default + SupervisorJob())`. Cancel it in `stop()`. Use `serverScope.launch { ... }` for the server loop. |
| **High** | `hpack/HpackDecoder.kt:85-99` | **HPACK integer decoder has no overflow guard — unbounded multi-byte integers cause `Int` overflow.** In `decodeInteger()`, the multi-byte continuation loop at L91-98 accumulates `value += (b and 0x7F) shl m` where `m` grows by 7 each iteration. For a maliciously crafted header block that sends 5+ continuation bytes, `m` reaches 35 and `value` overflows a 32-bit `Int` silently (wrapping in Kotlin). A value of `0x80 0x80 0x80 0x80 0x80 0x80...` in a loop can make the loop run indefinitely (each byte has the continuation bit set) until the data array is exhausted or the index corrupts. | Add: (1) a limit check `if (m >= 28) throw Http2Exception(COMPRESSION_ERROR, "Integer overflow")` — 28 bits is sufficient for all valid HPACK integers; (2) validate that the final decoded index does not exceed reasonable bounds before calling `lookupIndex()`. |
| **High** | `middleware/RateLimitMiddleware.kt:18-19` | **Rate limit IP extraction trusts `X-Forwarded-For` header without validation — trivial bypass.** The middleware reads `request.headers["X-Forwarded-For"]?.split(",")?.first()?.trim()` as the client IP. An attacker can set `X-Forwarded-For: 1.2.3.4` to impersonate a different IP or clear their own history. The only safe approach when this middleware runs directly on a public-facing server (no trusted reverse proxy) is to use the actual socket remote address. | Either: (a) require that consumers pass a `trustedProxies: Set<String>` config and only trust `X-Forwarded-For` when the actual remote address is in the trusted set; or (b) add a `useRemoteAddress: Boolean = false` option and warn in docs that the default XFF-based mode is only safe behind a trusted proxy. The current default is insecure for direct deployments. |
| **High** | `websocket/WebSocket.kt:135` | **`isOpen()` reads `_state` without holding `stateMutex` — unsynchronized raw field access.** `fun isOpen() = _state == WebSocketState.OPEN` reads the non-volatile `private var _state` directly without a lock. `WebSocketClient` also reads `state` without locking at L98 (`fun isConnected() = state == WebSocketState.OPEN`). All state transitions use `stateMutex.withLock`, but these external reads bypass it, creating a TOCTOU race between reading state and acting on it (e.g., the check at L73: `if (getState() != WebSocketState.OPEN) throw ...` is a suspend fun requiring lock, but `isOpen()` is not). | Mark `_state` with `@Volatile`, or change `isOpen()` to call `stateMutex.withLock { _state == WebSocketState.OPEN }` (making it `suspend`). Alternatively, use a `MutableStateFlow<WebSocketState>` and expose `.value` directly, which is thread-safe by design. |
| **Medium** | `http2/Http2Connection.kt:103-106` | **`maxConcurrentStreams` check uses `streams.size` which includes half-closed-local streams.** A stream in `HALF_CLOSED_LOCAL` state (server sent response, waiting for client END_STREAM) still occupies a slot in `streams` and still counts toward the limit. This is correct per RFC 7540, but streams are never proactively cleaned up until `endStreamSent && endStreamReceived` — if the client keeps streams half-open, the server will hit this limit and refuse new streams via `REFUSED_STREAM`. | Ensure `streams` cleanup is thorough. In `sendResponse()` at L236, when `endStreamReceived` is already true, the stream is removed. But if the client has not yet sent END_STREAM before the server sends the response, the stream stays in the map permanently if the client abandons it without sending END_STREAM. Add an idle-stream timeout sweep (e.g., in a periodic coroutine) to reclaim abandoned half-open streams. |
| **Medium** | `http2/Http2Connection.kt:150` | **`stream.dataChannel.trySend()` silently drops DATA frames when channel is full.** `Channel.BUFFERED` defaults to a capacity of 64 on JVM. Under rapid data reception, `trySend()` returns `ChannelResult.failure()` if the channel is full, and the frame payload is silently dropped with no FLOW_CONTROL_ERROR or RST_STREAM sent to the peer. The flow control window is already consumed at L140-143 before the trySend, so the window is decremented for data that was dropped. | Use `channel.send(frame.payload)` (suspending) inside a coroutine, or check `trySend` result and throw `Http2Exception(FLOW_CONTROL_ERROR, ...)` on failure so the connection-level error path triggers correctly. |
| **Medium** | `http2/Http2Connection.kt:112` | **HPACK decoder is shared across streams — not safe for concurrent use.** `hpackDecoder` is a single instance on `Http2Connection` accessed from `handleHeaders()` (L112) and `handleContinuation()` (L128). Both are called from the single frame-reading loop (synchronously), so this is safe today. However, HPACK decoder has mutable state (`dynamicTable`). If the architecture changes to handle HEADERS concurrently, this will be a data race. Add a comment documenting the single-loop invariant. | Add a comment `// HpackDecoder is NOT thread-safe; safe here because all frame reading is single-threaded in the run() loop`. This is documentation, not a code change, but prevents future regression. |
| **Medium** | `http2/Http2Settings.kt:62-65` | **Unknown SETTINGS IDs silently ignored — correct per spec, but no validation of value ranges.** RFC 7540 Section 6.5.2 specifies that `INITIAL_WINDOW_SIZE` must be <= 2^31-1 (0x7FFFFFFF), and `MAX_FRAME_SIZE` must be between 16384 and 2^24-1. Neither is validated during `decode()`. A peer sending `INITIAL_WINDOW_SIZE = 0xFFFFFFFF` (which exceeds Int.MAX_VALUE when cast as signed) will silently corrupt `settings.initialWindowSize`. | Add validation in `decode()`: after parsing, if `id == INITIAL_WINDOW_SIZE && value > 0x7FFFFFFF` throw `Http2Exception(FLOW_CONTROL_ERROR, ...)`. If `id == MAX_FRAME_SIZE && (value < 16384 || value > 16777215)` throw `Http2Exception(PROTOCOL_ERROR, ...)`. |
| **Medium** | `websocket/WebSocket.kt:81` | **WebSocket close sequence has a hardcoded 100ms delay that may not be sufficient.** `delay(100)` after sending the CLOSE frame at L81 assumes the peer will process the frame and the send queue will flush within 100ms. On a congested network or slow peer, the socket is forcibly closed before the CLOSE frame is fully written. The `outgoingChannel.send(WebSocketFrame.close(...))` may not have been processed by `sendJob` when the delay expires. | Wait for the send job to complete rather than using a time-based heuristic: after `outgoingChannel.send(...)`, close the `outgoingChannel` and use `sendJob?.join()` with a timeout of 5 seconds. This ensures the CLOSE frame is flushed before the socket is torn down. |
| **Medium** | `websocket/WebSocketParser.kt:19-20` | **127-length payload reads a signed `readLong()` — negative values possible if MSB is set.** `payloadLength = source.readLong()` reads a signed 64-bit integer. RFC 6455 specifies the 64-bit payload length as unsigned. If a peer sends a payload length with bit 63 set (which a spec-compliant peer would never do, but a malicious one might), `payloadLength` becomes negative, bypassing the `maxMessageSize` check at L23 (negative < positive is false) and causing `source.readByteArray(payloadLength)` to pass a negative `Long` which throws an `IllegalArgumentException`. The existing guard at L20 (`if (payloadLength < 0) throw ...`) is correct only for the 64-bit path. | The existing guard is correct: `if (payloadLength < 0) throw WebSocketException("Payload length too large")`. Verify this guard actually fires before the `maxMessageSize` check. Looking at L20-24: the negative check and the `maxMessageSize` check are both present. However, they are in a `when` block continuation, not ordered. Confirm that L20 guard triggers before the max size comparison at L23. Current order is correct, but add a comment to make the intent clear. |
| **Medium** | `middleware/CorsMiddleware.kt:25-26` | **`joinToString` uses default separator (`, `) for `Access-Control-Allow-Methods` but comma-only separator for `Access-Control-Allow-Headers`.** `config.allowedMethods.joinToString { it.name }` (L25) uses the default `separator = ", "` (via the transform overload) but `config.allowedHeaders.joinToString()` (L26) also uses `", "` as the default separator. Both are actually correct. However, there is a subtle spec issue: the CORS preflight response does NOT include `Vary: Origin` when reflecting the origin exactly. Without a `Vary` header, a caching proxy may return the same preflight response to a different origin, breaking CORS for subsequent cross-origin requests. | Add `headers["Vary"] = "Origin"` in `createPreflightResponse()` and `addCorsHeaders()` when a non-wildcard origin is reflected. This is a correctness issue with caching proxies, not a browser issue. |
| **Medium** | `middleware/CorsMiddleware.kt:41` | **Wildcard `allowedOrigins = setOf("*")` combined with `allowCredentials = true` is a CORS spec violation.** RFC CORS prohibits `Access-Control-Allow-Credentials: true` when `Access-Control-Allow-Origin: *`. The default `CorsConfig` has `allowedOrigins = setOf("*")` and `allowCredentials = false` — safe. But `permissiveCors()` helper at L45 calls `CorsMiddleware(CorsConfig(allowedOrigins = setOf("*")))` which uses `allowCredentials = false` — also safe. However, nothing prevents a caller from constructing `CorsConfig(allowedOrigins = setOf("*"), allowCredentials = true)`. | Add a `require` check in `CorsConfig` constructor: `require(!(allowedOrigins.contains("*") && allowCredentials)) { "CORS: allowCredentials=true cannot be combined with wildcard origin" }`. |
| **Medium** | `server/HttpParser.kt:33` | **Header names are not lowercased — duplicate headers with different case are stored as separate entries.** `headers[line.substring(0, colonIndex).trim()] = line.substring(colonIndex + 1).trim()` preserves case. Clients that send `Content-Type` and `content-type` in separate headers (unusual but legal) will be stored separately. More practically, downstream code uses `headers["Content-Type"]` (capital) and `headers["content-type"]` (lowercase) inconsistently across the codebase — for example, `HttpRequest.isKeepAlive` checks `headers["Connection"]` (capital C) while `ResponseParser` stores headers as received. | Normalize header names to lowercase in the parser: `headers[line.substring(0, colonIndex).trim().lowercase()] = line.substring(colonIndex + 1).trim()`. Update all header lookups in the codebase to use lowercase keys consistently. |
| **Medium** | `server/HttpParser.kt:28-29` | **`MAX_HEADER_SIZE` check accumulates `requestLine.length + header line lengths` but excludes CRLF bytes.** The actual HTTP wire size of headers is always at least 2 bytes larger per line (CRLF), so the effective limit is higher than intended. `MAX_HEADER_SIZE = 8192` with the current check allows header sections slightly larger than 8192 bytes to pass. This is a minor off-by-a-factor issue, not a security gap, but the guard doesn't precisely match the stated intent. | Either document that `MAX_HEADER_SIZE` is a character count (not byte count), or add 2 per line to `totalHeaderSize`. |
| **Medium** | `client/RealHttpClient.kt:19` | **`X-Forwarded-For` header not sanitized before sending in client requests.** `buildHeaders()` passes all `request.headers` through directly. If a caller constructs a `ClientRequest` with a spoofed `X-Forwarded-For` to a server that trusts that header, the client becomes a vector for origin spoofing against HTTPAvanue-backed servers. | This is a client-side concern and acceptable by design (callers control headers). Add a documentation note that callers are responsible for header values. No code change required, but add a `// Warning: headers are sent as-is` comment in `buildHeaders()`. |
| **Medium** | `ios/platform/Socket.ios.kt:39` | **iOS Socket uses `gethostbyname()` for DNS resolution — deprecated and not IPv6-capable.** `gethostbyname()` is deprecated in POSIX (superseded by `getaddrinfo()`). It does not support IPv6 addresses, returns only the first result, and is not thread-safe on some platforms. Modern POSIX networking should use `getaddrinfo()`. | Replace the `gethostbyname()` call with `getaddrinfo()`, iterating the returned address list and trying each address. This also enables dual-stack IPv4/IPv6 connectivity. |
| **Medium** | `websocket/WebSocketClient.kt:64-67` | **Reconnect monitoring loop spins with `delay(1000)` — wastes a coroutine for the entire connection lifetime.** The reconnect monitor at L64-67 runs `while (state == WebSocketState.OPEN) delay(1000)` polling once per second to detect a disconnection. This is unnecessary because the `receiveJob` in `WebSocket` already catches exceptions and transitions state. | Replace the polling loop with a `webSocket!!.messages.collect {}` flow that catches `CancellationException` — when the receive loop ends, the flow will complete, and reconnection can be triggered at that point without any polling. |
| **Low** | `hpack/HpackDynamicTable.kt:13` | **Dynamic table entry size uses string `.length` (character count) instead of byte count.** RFC 7541 Section 4.1 defines entry size as `name.length + value.length + 32` where lengths are in **octets** (bytes), not Unicode code points. For headers containing multi-byte UTF-8 characters, `String.length` in Kotlin returns the character count, not the UTF-8 byte count. This causes the table to undercount entry sizes, allowing more entries than the peer configured. | Replace `name.length + value.length + 32` with `name.encodeToByteArray().size + value.encodeToByteArray().size + 32`. In practice, HTTP headers are ASCII-only and this is a theoretical issue, but RFC compliance requires byte counting. |
| **Low** | `http2/Http2FrameCodec.kt:98` | **`sink.flush()` called after every frame write — excessive syscall pressure under high load.** `writeFrame()` calls `sink.flush()` unconditionally. Okio's `BufferedSink` already buffers; flushing after every frame forces a write syscall per frame. For a response with 100 DATA frames, this is 100 flush calls. | Flush only at the end of a logical response unit (after the final DATA+END_STREAM frame) or after each HEADERS frame. Change `writeFrame()` to omit the flush, and call `sink.flush()` in `sendResponse()` after the last DATA frame. |
| **Low** | `http2/Http2FrameCodec.kt:87` | **`writeFrame()` uses `require()` which throws `IllegalArgumentException`, not an `Http2Exception`.** If a caller passes a payload exceeding `MAX_MAX_FRAME_SIZE`, the `require()` at L87 throws `IllegalArgumentException` rather than `Http2Exception(FRAME_SIZE_ERROR)`. The caller's `try { ... } catch (e: Http2Exception)` block in `dispatchRequest()` will not catch this, causing an unhandled exception that propagates out of the stream coroutine. | Replace `require(length <= MAX_MAX_FRAME_SIZE) { ... }` with `if (length > MAX_MAX_FRAME_SIZE) throw Http2Exception(Http2ErrorCode.FRAME_SIZE_ERROR, "Payload too large: $length")`. |
| **Low** | `server/HttpServer.kt:79-84` | **Exception type detection via `e::class.simpleName` string comparison is fragile.** The shutdown detection at L79 compares `e::class.simpleName == "SocketException"`. If the JVM implementation changes the exception class name, or if the exception is wrapped, this check silently fails and the error is logged. | Catch the exception by type: add `} catch (e: java.net.SocketException) { ... }` at the platform level. Since `HttpServer.kt` is in `commonMain`, the platform-specific check should be in the `androidMain`/`desktopMain` expect/actual for `SocketServer.accept()`. The server loop in `commonMain` should only catch `CancellationException` and a generic platform-neutral exception. |
| **Low** | `middleware/BodyParserMiddleware.kt:8` | **`BodyParserMiddleware` is a no-op pass-through.** The middleware accepts `json: Json` in its constructor but does nothing in `handle()` — it just calls `next(request)`. The actual parsing utilities (`parseJson`, `bodyAsText`) are extension functions that callers must invoke manually. The middleware's existence implies automatic body parsing, but it provides none. This is misleading. | Either implement automatic content-type-based body parsing (e.g., for `application/json`, parse the body into a `JsonElement` and attach it to `HttpRequest.context`), or remove `BodyParserMiddleware` and document that `parseJson()` / `bodyAsText()` are the intended pattern. |
| **Low** | `http2/Http2Connection.kt:57` | **`PRIORITY` frames are silently discarded with a comment "Advisory only, ignored".** RFC 7540 Section 5.3 states that servers SHOULD use priority hints to schedule responses. Ignoring them is allowed by the spec but means the server provides no response prioritization. For a production server serving web content, this results in suboptimal perceived loading performance. | Note this as a known limitation in a `// TODO(performance): implement priority scheduling` comment. No code change required unless performance becomes a concern. |
| **Low** | `websocket/WebSocket.kt:37-38` | **`BufferOverflow.DROP_OLDEST` on both channels means messages silently dropped under backpressure.** If the sender is faster than the consumer (`incomingChannel` full) or the network is slower than the application (`outgoingChannel` full), messages are silently dropped without any notification. The capacity of 100 is arbitrary. | Change `outgoingChannel` to `Channel.UNLIMITED` or `Channel.CONFLATED` depending on requirements, and log a warning when `trySend` results in a drop so application code is aware. For the incoming channel, consider suspending (blocking the receiver) rather than dropping. |
| **Low** | `auth/AuthenticationManager.kt` | **`AuthenticationManager` is an interface with no validation logic — completely delegated to caller.** The library provides an auth middleware but ships no default token validation implementation. There is no `JwtAuthManager`, `HmacAuthManager`, or even an in-memory test implementation. Callers must implement `fun validateToken(token: String): TokenValidation` themselves. | Provide at least a `HmacSha256AuthManager(secret: String)` implementation as part of the library. This removes the implementation burden from every caller and ensures the auth pattern is used correctly. |
| **Low** | `sse/SseEmitter.kt:34` | **`closed` is a `var Boolean` with private setter — visible but not `@Volatile`.** `closed` is read by `send()` (inside `if (!closed)`) and by `SseConnectionManager.broadcast()` without any lock. The `closed` field could be stale in another thread. While Kotlin `var` on JVM is not guaranteed to be visible across threads without `@Volatile`, in practice the `Channel.close()` at L50 typically provides a happens-before edge. The formal correctness risk is low but the annotation is missing. | Mark `var closed = false` as `@Volatile private var closed = false`. |

---

## Confirmed from Previous Network/System Review (do not re-discover)

The following issues were first documented in `docs/reviews/NetworkSystem-Review-SevenModules-260220-V1.md` and are confirmed again in this deep review with line-level specificity:

- `Http2Connection.kt`: sink not synchronized (CRITICAL — row 1 above with full detail)
- `HpackDecoder.kt`: Huffman not implemented (CRITICAL — row 2 above)
- `StaticFileMiddleware.kt`: path traversal (CRITICAL — row 3 above)

---

## Recommendations

1. **Fix sink synchronization before any HTTP/2 testing.** Add `sinkMutex` to `Http2Connection`. Without this, every multi-stream test will produce corrupt responses. This is a 5-line fix.

2. **Implement Huffman decoding or disable HTTP/2 until implemented.** The Huffman stub is a Rule 1 violation. Either implement it (the RFC 7541 Appendix B table is public domain, ~60 lines for a correct decoder) or add a SETTINGS frame at startup to negotiate `HEADER_TABLE_SIZE = 0` which discourages Huffman but does not disable it. The only reliable fix is implementation.

3. **Add `..` traversal check to `StaticFileMiddleware` immediately.** The fix is 3 lines. While Android and iOS platform implementations are bounded by their asset systems, Desktop is not and this middleware should be correct independently of platform.

4. **Add `Vary: Origin` to CORS responses.** Missing `Vary` header causes proxy caches to serve wrong CORS responses to different origins. 1-line fix in `CorsMiddleware`.

5. **Normalize header names to lowercase in `HttpParser`.** The header case inconsistency is a latent bug that manifests when clients send non-standard casing. Fixing this now prevents subtle downstream failures.

6. **Migrate iOS DNS from `gethostbyname` to `getaddrinfo`.** The current implementation fails for IPv6 addresses and is deprecated. This is a 20-line change in `Socket.ios.kt`.

7. **Replace polling reconnect loop with flow-based detection in `WebSocketClient`.** The `delay(1000)` polling loop is wasteful. Replace with message flow completion detection.

8. **Add `@Volatile` to `SseEmitter.closed` and `WebSocketClient._state`/`state`.** Low-effort correctness improvement for thread visibility.

9. **Remove or implement `BodyParserMiddleware`.** As a no-op pass-through it is misleading. Either implement it or remove it and document the extension function pattern.

10. **Add HPACK dynamic table size re-sync after SETTINGS update.** The encoder's table stays at the construction-time size even if the peer negotiates a smaller table via SETTINGS.

---

## What Is Correct and Should Not Be Changed

- **HTTP/1.1 request parsing** (`HttpParser.kt`): correct request line parsing, header parsing, chunked transfer encoding, and body size limits.
- **WebSocket handshake** (server + client): correct SHA-1 key generation, RFC 6455 `Sec-WebSocket-Accept` computation, and protocol selection.
- **WebSocket fragmentation handling** (`WebSocket.kt`): correct reassembly, timeout detection, and size limit enforcement for fragmented messages.
- **Flow control arithmetic** (`Http2FlowControl.kt`, `Http2Stream.kt`): overflow checks are correct (`toLong()` before addition), `Int.MAX_VALUE` guard is correct.
- **HTTP/2 frame codec** (`Http2FrameCodec.kt`): correct 9-byte header encoding/decoding, correct stream ID mask (`and 0x7FFFFFFF`), correct GOAWAY/PING/WINDOW_UPDATE encoding.
- **HPACK static table** (`HpackStaticTable.kt`): all 61 entries are correct per RFC 7541 Appendix A.
- **HPACK integer encoding** (`HpackEncoder.kt`): correct multi-byte encoding per RFC 7541 Section 5.1.
- **TLS configuration** (`TlsConfig.kt`, `Socket.android.kt`, `Socket.desktop.kt`): BouncyCastle PEM parsing, hostname verification, TLSv1.2/1.3 enforcement, and client cert validation are all correct.
- **Connection pooling** (`RealHttpClient.kt`): thread-safe via `Mutex`, expiry logic correct, LIFO eviction correct.
- **Rate limiting** (`RateLimitMiddleware.kt`): token bucket algorithm is mathematically correct; `Mutex` guarding of bucket map is correct. The only issue is IP extraction trust (documented above as High).
- **HTTP response serialization** (`HttpResponse.toBytes()`, `toChunked()`): correct wire format, chunked encoding is correct.
- **Route matching** (`RouteRegistry.kt`, `RoutePattern.kt`): static/dynamic split is correct, parameter extraction is correct.
- **KMP structure**: all platform-specific code is correctly placed in `androidMain`, `iosMain`, `desktopMain`. No Android imports in `commonMain`.
- **No Rule 7 violations**: no AI attribution found in any of the 68 files.

---

## Totals

| Severity | Count |
|----------|-------|
| Critical | 3 |
| High | 8 |
| Medium | 11 |
| Low | 10 |
| **Total** | **32** |

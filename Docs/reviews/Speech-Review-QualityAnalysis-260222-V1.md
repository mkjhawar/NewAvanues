# Speech Layer Quality Analysis — 260222 V1

Modules reviewed: SpeechRecognition (93 kt), VoiceIsolation (7 kt), Whisper (12 kt), Voice/WakeWord (13 kt)
Branch: VoiceOS-1M-SpeechEngine
Reviewer: code-reviewer agent

---

## Summary

The speech layer is architecturally sound at the abstraction level and shows clear intent around KMP parity, VAD correctness, and confidence scoring. However several concrete issues threaten production reliability: a stub wake-word detector that silently reports success, thread-safety holes in the audio capture pipeline and LearningSystem, a hardcoded external-storage path that violates Android scoped-storage rules, a non-functional model download button in the UI, an audio queue that is never rebuilt after reconnect, and multiple Rule 7 (no AI attribution) violations in file headers.

---

## Issues

| Severity | File:Line | Issue | Suggestion |
|----------|-----------|-------|------------|
| Critical | `Voice/WakeWord/.../PhonemeWakeWordDetector.kt:38` | **Rule 7 violation**: `author: Claude Code` in file header comment at L1 (original filename header, not package comment). Author field must be "Manoj Jhawar". | Remove `Claude Code` attribution; set `@author Manoj Jhawar`. |
| Critical | `Voice/WakeWord/.../IWakeWordDetector.kt:3` | **Rule 7 violation**: `// author: Claude Code` in file header. | Replace with `Manoj Jhawar`. |
| Critical | `Voice/WakeWord/.../IWakeWordSettingsRepository.kt:3` | **Rule 7 violation**: `// author: Claude Code` in file header. | Replace with `Manoj Jhawar`. |
| Critical | `Voice/WakeWord/.../PhonemeWakeWordDetector.kt:76-121` | **Stub detector reports success**: `initialize()` / `start()` return `Result.Success` and transition to `LISTENING` state but perform zero audio capture or phoneme extraction. `WakeWordService` launches on this detector, broadcasts `WAKE_WORD_DETECTED` intents that will never arrive. The entire wake-word feature is silently non-functional. | Must implement phoneme audio capture loop or gate the feature behind a `BuildConfig.FEATURE_WAKE_WORD` flag and refuse initialization with an explicit error. Do NOT emit `Result.Success` from a no-op. |
| Critical | `SpeechRecognition/.../whisper/WhisperModelDownloadScreen.kt:169` | **Download button is dead**: `onDownload = { /* trigger from ViewModel/coroutine scope */ }` — the lambda is an empty comment. Tapping "Download" does nothing. The UI compiles, the button renders, but no download is ever triggered. | Wire to a `ViewModel.downloadModel(modelSize)` call. The `WhisperModelManager` already has a real `downloadModel()` implementation. |
| Critical | `SpeechRecognition/.../googlecloud/GoogleCloudStreamingClient.kt:411-413` | **Audio queue not rebuilt after reconnect**: `audioQueue` is a `Channel.UNLIMITED` created once at construction time. `stopStreaming()` calls `audioQueue.close()` (L135), making it permanently closed. On reconnect (e.g., after a 4:50 minute stream rotation), `streamLoop` calls `performStreamSession` again, but `tryReceive()` on a closed channel always returns `isFailure`/`isClosed`, so no audio is ever sent in the new session. Recognition silently stops working after the first stream rotation. | Recreate `audioQueue = Channel(Channel.UNLIMITED)` at the start of each new session in `performStreamSession`, or use a single non-closing channel with a sentinel value for stop. |
| High | `SpeechRecognition/.../googlecloud/GoogleCloudStreamingClient.kt:234` | **`Thread.sleep(10)` inside `writeTo(BufferedSink)`**: `writeTo()` runs on OkHttp's I/O executor thread. Calling `Thread.sleep()` blocks the thread in a tight loop when no audio is ready, starving the thread pool under concurrent streams and making this incompatible with coroutine structured concurrency (sleeping cannot be cancelled). | Replace with coroutine `delay()` or redesign the drain loop to use a `BufferedChannel.receive()` with a timeout: `val chunk = withTimeoutOrNull(10) { audioQueue.receive() }`. |
| High | `SpeechRecognition/.../WhisperModelManager.kt:397-400` | **External storage path `/sdcard/ava-ai-models/`**: `getSharedModelsDir()` uses `Environment.getExternalStorageDirectory()`. On Android 10+ (API 29+), direct access to `Environment.getExternalStorageDirectory()` requires `READ_EXTERNAL_STORAGE` / `WRITE_EXTERNAL_STORAGE` (deprecated in API 29, unavailable to normal apps on API 30+ without `MANAGE_EXTERNAL_STORAGE`). Models will silently fail to save/load on modern devices. | Use `context.getExternalFilesDir(null)` for app-private external storage (no permission needed), or define a ContentProvider for truly shared access. Flag the shared-storage design in a comment if cross-app sharing is intentional. |
| High | `SpeechRecognition/.../LearningSystem.android.kt:30-31` | **Unsynchronized mutable state accessed from multiple coroutines**: `learnedCommands` (`mutableMapOf`) and `confidenceHistory` (`mutableListOf`) are accessed from `processWithLearning` (called from `scope.launch` in `AndroidSTTEngine.processRecognitionResult`, which runs on `Dispatchers.IO`), `recordSuccess`, and `recordFailure`. No synchronization. Data corruption possible under load. | Use `ConcurrentHashMap` for `learnedCommands` and a `synchronized` block or `CopyOnWriteArrayList` for `confidenceHistory`, or run all mutation on a single-threaded dispatcher. |
| High | `SpeechRecognition/.../VoiceStateManager.kt:46-52` | **`AtomicBoolean` fields wrapped in `@Volatile` annotation — redundant and misleading**: `@Volatile private var _isVoiceEnabled = AtomicBoolean(true)`. `AtomicBoolean` is already thread-safe; the `@Volatile` on the reference variable is harmless but signals that the author may have conflated the two mechanisms. More importantly, `_voiceState.value = newState` is called inside `stateLock.write {}` (L459). `StateFlow.value` mutation inside a `ReentrantReadWriteLock` write section is safe (non-blocking) but readers collecting from `_voiceState` on a different coroutine may observe the old value until the write lock releases — no bug in practice, but the debounce logic (L444-447) means rapid state changes silently skip updates. | Remove `@Volatile` from `AtomicBoolean` references. Document the debounce skip behavior explicitly. |
| High | `SpeechRecognition/.../SdkInitializationManager.kt:6` | **Rule 7 violation**: `Author: VOS4 Development Team` — per known stub inventory memory this is a Rule 7 violation pattern. While "VOS4 Development Team" is not an AI name, the pattern from MEMORY.md marks this as a violation category. More importantly the file has no `@author Manoj Jhawar` marker. | Set author to `Manoj Jhawar`. |
| High | `SpeechRecognition/.../androidMain/whisper/WhisperAudio.kt:258-265` | **OOM risk under sustained audio**: `audioBuffer` grows as `ArrayList<Float>`. The overflow protection (L259-264) drops oldest samples when `audioBuffer.size + samplesRead > maxBufferSamples`. However, `audioBuffer.subList(0, excess).clear()` is O(n) because clearing a subList of an ArrayList shifts the remaining elements. At 16kHz × 60s = 960,000 floats (~3.7MB), this O(n) operation runs on every read cycle once the buffer is full. | Replace `ArrayList<Float>` with a circular `FloatArray` ring buffer, or use a `LinkedList`-based deque with head-pointer arithmetic. |
| High | `Voice/WakeWord/.../WakeWordService.kt:163-177` | **Coroutine launched after `onDestroy` / after scope cancel**: `onDestroy` launches `serviceScope.launch { wakeWordDetector.stop(); wakeWordDetector.cleanup() }` then immediately calls `serviceScope.cancel()`. The launched coroutine competes with the cancel — it may be cancelled before `stop()`/`cleanup()` execute, leaking any audio resources the stub holds. | Use `runBlocking { wakeWordDetector.stop(); wakeWordDetector.cleanup() }` in `onDestroy` instead, or use `scope.launch { ... }.invokeOnCompletion { scope.cancel() }` to ensure cleanup runs first. |
| Medium | `SpeechRecognition/.../googlecloud/GoogleCloudStreamingClient.kt:95` | **`H2_PRIOR_KNOWLEDGE` in protocol list includes `HTTP_1_1`**: `protocols(listOf(H2_PRIOR_KNOWLEDGE, HTTP_1_1))` — H2_PRIOR_KNOWLEDGE means "only speak HTTP/2, no upgrade negotiation". Including `HTTP_1_1` in the same list is contradictory; OkHttp 4.x may fall back to HTTP/1.1 if the server doesn't speak h2c, defeating the streaming design. Google Cloud STT v2 REST streaming endpoint expects HTTP/2. | Use `protocols(listOf(H2_PRIOR_KNOWLEDGE))` exclusively, or use `H2` (with TLS) and rely on ALPN negotiation. Document the choice. |
| Medium | `VoiceIsolation/.../VoiceIsolation.ios.kt:32-38` | **`initialize()` returns `true` with no audio processing wired**: iOS implementation is documented as a stub (comment `TODO: Initialize AVAudioEngine`) but returns `true` unconditionally and sets `isActive = true` in the state flow. Callers cannot distinguish between "isolation active" and "stub passthrough", potentially hiding missing noise suppression in production. | Return `false` when not implemented, or document the known behavior in `getAvailability()` and ensure `isActive` is set to `false` when no processing is actually running. |
| Medium | `VoiceIsolation/.../VoiceIsolation.desktop.kt:32-38` | Same issue as iOS: desktop `initialize()` returns `true` with `TODO` for actual processing. | Same fix as iOS. |
| Medium | `SpeechRecognition/.../whisper/WhisperVAD.kt:77` | **`paddingBuffer` capacity may be undersized**: `ArrayDeque<Float>(paddingMs.toInt() * sampleRate / 1000)`. For default values (150ms, 16000Hz) this gives `150 * 16000 / 1000 = 2400` elements — correct. But for large `paddingMs` values (e.g., 1000ms), `Int` arithmetic may overflow: `1000 * 16000 / 1000 = 16000`, no overflow — but for `paddingMs > 134_217` ms the multiplication overflows Int. This is a very large value but the constructor is public. | Compute `maxPaddingSamples` using `Long` arithmetic: `(paddingMs * sampleRate / 1000L).toInt()`. |
| Medium | `SpeechRecognition/.../ConfidenceScorer.kt:93-94` | **Comment/constant mismatch**: Comment at L86 says "Vivoka SDK returns confidence in 0-100 scale" but the constant `VIVOKA_MAX_SCORE = 10000f` is used for normalization (i.e., division by 10000). Either the comment is wrong (scale is 0-10000, not 0-100) or the constant is wrong. Previous memory notes confirm scale is 0-10000, so the comment at L86 is incorrect. | Fix the comment: "Vivoka VSDK returns confidence in 0-10000 range". |
| Medium | `SpeechRecognition/.../AndroidSTTEngine.kt:473` | **`CoroutineScope` with `SupervisorJob` created at destroy time, never cancelled**: `CoroutineScope(Dispatchers.Main.immediate + SupervisorJob()).launch { recognizer.destroy() }` — a fire-and-forget scope that is never saved or cancelled. If `destroy()` is called multiple times, or if the VM is reclaimed before `recognizer.destroy()` completes, the coroutine leaks. | Store the one-shot scope in a local variable and attach `invokeOnCompletion` to cancel it, or use `MainScope().launch { ... }.also { it.invokeOnCompletion { it.cancel() } }`. |
| Medium | `SpeechRecognition/.../WhisperModelManager.kt:286-289` | **`outputStream`/`inputStream` not closed in finally**: While `CancellationException` and general `Exception` paths close the streams manually, any exception thrown between `outputStream.flush()` (L322) and `outputStream.close()` (L323) would leave the stream open. | Move `outputStream.use { ... }` with `inputStream` also in a `use` block, or add a `finally` clause that closes both streams unconditionally. |
| Medium | `SpeechRecognition/.../WhisperModelManager.kt:398` | **`getSharedModelsDir()` called inside `withContext(Dispatchers.IO)` but also from main thread via `getDownloadedModels()` and `getModelPath()`**: `getSharedModelsDir()` calls `dir.mkdirs()` (an I/O operation). When called from `getDownloadedModels()` on the main thread (which is what `WhisperModelDownloadScreen` does via `remember {}`), it does disk I/O on the main thread. | Ensure `getSharedModelsDir()` is only called from IO dispatcher contexts, and use `LaunchedEffect` or a ViewModel for the `remember {}` calls in the screen. |
| Medium | `SpeechRecognition/.../androidMain/whisper/WhisperEngine.kt:205-209` | **`stopListening()` launches a coroutine from a potentially-cancelled scope**: After `listenJob?.cancel()`, `scope.launch { transcribeChunk(remainingAudio) }` runs on `scope`. If `destroy()` has been called (which cancels `scope`), this launch silently does nothing — the final audio chunk is discarded. This is a data-loss edge case. | Check `scope.isActive` before launching: `if (scope.isActive) scope.launch { ... }`. |
| Low | `Voice/WakeWord/.../WakeWordSettingsRepository.kt:60` | **`WakeWordKeyword.valueOf()` can throw `IllegalArgumentException`** if the stored string does not match any enum name (e.g., after a rename). | Wrap in `runCatching { WakeWordKeyword.valueOf(...) }.getOrDefault(WakeWordKeyword.HEY_AVA)`. |
| Low | `SpeechRecognition/.../WhisperModelDownloadScreen.kt:81-82` | **`remember { }` for values that change**: `downloadedModels` and `availableStorageMB` are computed once at initial composition via `remember {}`. They will not update when a model is downloaded or storage changes. | Replace with `produceState` or observe from a ViewModel `StateFlow` so the list refreshes after a download completes. |
| Low | `SpeechRecognition/.../whisper/WhisperVAD.kt:265-271` | **Division in `computeFrameRMS` may divide by zero**: `sqrt(sumSquares / (end - offset))` — if `end == offset` (e.g., `length == 0` is passed), this divides by zero, producing `NaN` which then propagates as `isSpeech = NaN > threshold`. In practice `FRAME_SIZE=160` prevents this, but the partial frame path (L114-119) uses `remaining = samples.size - offset` which can be 0 if `samples.size` is a multiple of `FRAME_SIZE`. | Guard: `if (end == offset) return 0f`. |
| Low | `SpeechRecognition/.../CommandCache.kt:74-78` | **LRU "eviction" is O(n) and incorrect**: Removing `keys.firstOrNull()` from a `LinkedHashMap` (the default `mutableMapOf()`) removes the first-inserted key, not the least-recently-used key. The comment says "LRU" but this is FIFO eviction. | Use `LinkedHashMap(initialCapacity, loadFactor, accessOrder=true)` wrapped in `synchronized`, or use a `java.util.LinkedHashMap` with `removeEldestEntry` override for proper LRU semantics. |
| Low | `SpeechRecognition/.../googlecloud/GoogleCloudStreamingClient.kt:406` | **`Math.pow` used instead of bitshift or `shl`**: `Math.pow(2.0, ...)` for integer exponential backoff — minor style issue. | Use `(1L shl reconnectAttempts - 1)` or `2.0.pow(...)` (kotlin.math). |
| Low | `SpeechRecognition/.../RecognitionResult.kt:32` | **`currentTimeMillis()` as a default parameter**: `val timestamp: Long = currentTimeMillis()` — this is evaluated at construction time (correct), but `currentTimeMillis()` is an `expect` function. Verify the commonMain `PlatformUtils.kt` `actual` for all platforms returns wall-clock ms, not monotonic clock. (No bug found; marking for explicit verification.) | Confirm `actual fun currentTimeMillis(): Long` returns `System.currentTimeMillis()` on Android/Desktop and `NSDate.timeIntervalSince1970 * 1000` on iOS. |

---

## Module-Level Notes

### VoiceIsolation (7 files)
- Android implementation is correct and solid: effects created on audio session, released on stop, graceful fallback when hardware effects unavailable.
- **iOS and Desktop are pass-through stubs** that silently claim `isActive = true`. Per Rule 1 these must either be implemented or return `false`/`isActive=false`.
- No resource leaks found: `disableAllEffects()` calls `.release()` on all three effect handles.
- Thread safety: `_state.value = ...` runs on whatever thread calls `toggle()`/`initialize()`. Android AudioEffect callbacks are on a native thread. No observed race between state mutation and effect callbacks (effects do not mutate `_state`).

### Voice / WakeWord (13 files)
- **Critical**: `PhonemeWakeWordDetector` is a complete stub that emits success signals. The `WakeWordService` is well-structured (battery monitoring, screen-off pause, foreground service) but all of it is predicated on a detector that never actually detects anything.
- `WakeWordViewModel` cleanly handles error results and exposes events — good architecture. Will work correctly once the detector is implemented.
- `WakeWordSettingsRepository` correctly uses DataStore but the `settings` flow mapping at L60 can throw `IllegalArgumentException` on stale enum values.
- Duplicate file structure: `src/commonMain/` and `src/main/java/` both contain `IWakeWordDetector.kt` and `WakeWordModels.kt`. The `src/main/java/` copies are Android-only legacy; their existence creates confusion about which types are canonical.

### Whisper (examples only in top-level Modules/Whisper)
- Only example app files exist at `Modules/Whisper/examples/`. These are sample code from the whisper.cpp Android demo, not production code. `WhisperLib.kt` and the recorder are the JNI bridge being vendored.
- `SpeechRecognition/androidMain/whisper/WhisperEngine.kt` + `WhisperNative.kt` are the production implementation — both reviewed above.

### SpeechRecognition (93 files)
- **Architecture is well-structured**: `SpeechEngine` enum + `SpeechRecognitionService` interface + platform factories follows the KMP expect/actual pattern correctly.
- **VAD (WhisperVAD)**: Energy-based, adaptive threshold, hangover timer — correct implementation. Shared in `commonMain`. The partial-frame path and the `computeFrameRMS` divide-by-zero edge case are minor.
- **ConfidenceScorer**: Unified normalization across 5 engines is correct. The VOSK dual-path (log-likelihood vs 0-1) is well-handled. Comment/constant mismatch for Vivoka is the only bug.
- **WhisperNative**: Thread safety via `synchronized(this)` object lock is correct for native-serial access. The `hasWarnedConfidence` sentinel and `CONFIDENCE_UNAVAILABLE = -1f` pattern is clean.
- **GoogleCloudEngine**: Dual-mode (VAD batch vs streaming) is solid. Reuse of `WhisperAudio`/`WhisperVAD` for the batch path is a good DRY decision.
- **`GoogleCloudStreamingClient`**: Audio queue not rebuilt on reconnect (Critical) and `Thread.sleep()` in `writeTo()` (High) are the two blockers.
- **`AndroidSpeechRecognitionService`**: Static `appContext` holder is an acceptable pattern given Android constraints, but it introduces a potential memory leak if context is set to a non-Application context (already guarded with `context.applicationContext` in the factory, but not enforced in `setContext()`).
- **`SdkInitializationManager`**: Solid coroutine-safe retry framework using `Mutex` (correct — not `ReentrantReadWriteLock` inside suspend, avoiding the deadlock bug seen in other modules). The `initScope` is long-lived which is intentional.
- **`VoiceStateManager`**: Competent but the `@Volatile AtomicBoolean` redundancy and debounce-skipping state updates are minor issues.
- **`LearningSystem`**: Unsynchronized maps are a real data-race risk on `Dispatchers.IO`.
- **`WhisperModelManager`**: Scoped-storage violation is the most critical. Resume download logic and SHA256 verification are solid. The OkHttp streaming download loop with `ensureActive()` is correct.
- **`WhisperModelDownloadScreen`**: Dead download button is a Critical functional bug. UI correctly uses `AvanueTheme.colors.*` and has AVID semantics on all interactive elements.
- **Test coverage**: 4 common tests + 3 androidUnit tests cover `RecognitionResult`, `SpeechConfig`, `WhisperConfig`, and `GoogleCloudConfig`. No tests for `WhisperVAD`, `ConfidenceScorer`, `LearningSystem`, or `CommandCache` — these have pure logic that is straightforward to unit-test.

---

## Recommendations

1. **Fix the three Critical Rule 7 violations immediately** — `IWakeWordDetector.kt`, `IWakeWordSettingsRepository.kt`, `PhonemeWakeWordDetector.kt` all carry `author: Claude Code` in file headers.

2. **Gate the wake-word feature**: `PhonemeWakeWordDetector.initialize()` must not return `Result.Success` and set state to `STOPPED` when no actual detector is initialized. Add a `BuildConfig.FEATURE_WAKE_WORD` guard or return `Result.Error(NotImplementedError(...))` with a clear message. This prevents the `WakeWordService` from launching and reporting false "listening" state.

3. **Fix the dead download button**: `WhisperModelDownloadScreen` `onDownload` lambda is empty. Wire it to a ViewModel that calls `modelManager.downloadModel(modelSize)` from a coroutine scope.

4. **Rebuild `audioQueue` on each streaming session**: Add `audioQueue = Channel(Channel.UNLIMITED)` at the start of `performStreamSession` (after the previous channel has been consumed/closed) to prevent the silent audio-starvation bug after the first 4:50 minute stream rotation.

5. **Replace `Thread.sleep(10)` in `writeTo()`**: This OkHttp callback runs on a thread-pool thread and cannot be cancelled. Redesign the audio-drain loop in `performStreamSession.writeTo()` to use a short `poll()` with a timeout, or restructure to a coroutine-based producer.

6. **Fix external storage path**: Replace `Environment.getExternalStorageDirectory()` with `context.getExternalFilesDir(null)` in `WhisperModelManager.getSharedModelsDir()` for Android 10+ scoped-storage compliance.

7. **Synchronize `LearningSystem` collections**: `learnedCommands` and `confidenceHistory` are mutated from coroutines on `Dispatchers.IO` without synchronization. Promote to `ConcurrentHashMap` and a synchronized list.

8. **Fix VoiceIsolation stubs**: iOS and Desktop `initialize()` must return `false` and set `isActive = false` in the state flow. They must not claim to be active when doing no processing.

9. **Add tests for VAD, ConfidenceScorer, CommandCache, LearningSystem** — these are pure logic classes with no platform dependencies and are straightforward to test in `commonTest`.

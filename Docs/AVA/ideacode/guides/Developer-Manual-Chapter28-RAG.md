# Chapter 28: RAG (Retrieval-Augmented Generation)

**Last Updated:** 2025-11-07
**Status:** 98% Complete (Phases 1-3.2 + Parsers + RAGChatEngine + Multilingual + Quantization + Adaptive UI)
**Authors:** AVA AI Team

---

## Table of Contents

- 28.1 RAG System Overview
- 28.2 Architecture and Design
- 28.3 Document Ingestion Pipeline
- 28.4 Vector Search Implementation
- 28.5 Performance Optimization (K-means Clustering)
- 28.6 Model Management
  - 28.6.1 External Model Loading
  - 28.6.2 Platform Detection
  - 28.6.3 Multilingual Models
  - 28.6.4 Model Quantization
  - 28.6.5 Model Registry
- 28.7 Usage and Integration
- 28.8 Performance Benchmarks
- 28.9 Document Management UI
  - 28.9.1 Screens (Document Management, RAG Chat, RAG Search)
  - 28.9.2 Adaptive Layout System
  - 28.9.3 Gradient Styling
  - 28.9.4 Animations
  - 28.9.5 ViewModels
  - 28.9.6 Design Decisions
- 28.10 Future Roadmap

---

## 28.1 RAG System Overview

### What is RAG?

Retrieval-Augmented Generation (RAG) enhances LLM responses by retrieving relevant context from a document corpus before generating answers. This enables AVA to:

- Answer questions from large document libraries (manuals, docs, PDFs)
- Provide accurate, source-backed responses
- Work offline with on-device processing
- Scale to 200k+ chunks with sub-50ms search

### Why RAG in AVA?

**Field Worker Use Case:**
```
Scenario: Electrician needs to troubleshoot a complex industrial system

Traditional: Search through 500-page manual, takes 10+ minutes
With RAG: Ask "How do I reset the thermal overload relay?"
          ‚Üí Instant answer with relevant manual sections (<1 second)
```

**Key Benefits:**
- **Offline-first:** No internet required for document search
- **Privacy:** Documents never leave device
- **Instant:** Sub-50ms search even with 200k chunks
- **Accurate:** Source-backed answers from actual documentation

### Current Status (Phase 3.2+)

‚úÖ **Operational:**
- **6 document formats:** PDF, DOCX, HTML (including web URLs!), Markdown, TXT, RTF
- **ONNX embedding generation:**
  - English: all-MiniLM-L6-v2 (384 dimensions)
  - Multilingual: 50+ languages supported
  - Quantized models: INT8 (75% smaller), FP16 (50% smaller)
- **Persistent SQLite storage with Room**
- **K-means clustering** (256 clusters, 40x speedup)
- **Two-stage search** (<50ms for 200k chunks)
- **Parallel processing pipeline** (50% faster indexing)
- **RAGChatEngine** for LLM integration
- **MLC-LLM Provider** for on-device chat
- **Complete Document Management UI** with Material 3
- **Model Registry System** with proprietary naming
- **Cross-lingual search** (query in one language, find in another)

‚úÖ **Model Support:**
- 3 English models (BASE, FAST, QUAL)
- 3 Multilingual models (50+ languages each)
- 2 Language-specific models (Chinese, Japanese)
- 15+ quantized variants (INT8/FP16)

‚è∏Ô∏è **In Development:**
- LRU cache (Phase 3.3)
- Advanced LLM features (Phase 4)
- Cloud sync (Supabase integration)

---

## 28.2 Architecture and Design

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     RAG SYSTEM ARCHITECTURE                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    INGESTION PIPELINE                   ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ PDF Parser ‚Üí Text Chunker ‚Üí Embedding Generator        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   (PdfBox)     (512 tokens)    (ONNX all-MiniLM-L6-v2) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚Üì                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ            ENCRYPTION LAYER (NEW: 2025-12-05)           ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ AES-256-GCM Encryption ‚Üí Android Keystore              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (embedding vectors)      (hardware-backed keys)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚Üì                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              STORAGE LAYER (SQLDelight)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ Documents Table  ‚Üí Chunks Table ‚Üí Clusters Table       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (metadata)         (encrypted embeddings) (centroids)  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    is_encrypted = 1                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    encryption_key_version = 1           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚Üì                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              SEARCH LAYER (Two-Stage)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ Stage 1: Find top-3 clusters (~1ms)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Stage 2: Decrypt & search chunks (~7ms with decrypt)   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Result: <50ms for 200k chunks (5-10% overhead)         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚Üì                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              LLM INTEGRATION (Phase 4)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ Context Assembly ‚Üí Gemma-2b-it ‚Üí Streaming Response    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (top 3-5 chunks)   (MLC-LLM)     (token-by-token)      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Security Layer (NEW: 2025-12-05)

All embedding vectors are now encrypted at rest using enterprise-grade encryption:

| Security Feature | Implementation |
|------------------|----------------|
| **Encryption Algorithm** | AES-256-GCM (military-grade) |
| **Key Storage** | Android Keystore (hardware-backed when available) |
| **Authentication** | 128-bit GCM authentication tag |
| **Key Rotation** | Supported with automatic re-encryption |
| **Document Integrity** | SHA-256 checksums for content verification |
| **Migration** | Automatic encryption of legacy unencrypted data |
| **Performance Impact** | 5-10% overhead (~2-5ms per chunk) |
| **Status** | Always enabled (cannot be disabled) |

**Components:**

- `EmbeddingEncryptionManager` - Core encryption/decryption engine
- `EncryptedEmbeddingRepository` - Transparent encryption wrapper
- `EncryptionMigration` - Batch migration from unencrypted to encrypted storage

**Related:** See [Chapter 73 - Production Readiness & Security](Developer-Manual-Chapter73-Production-Readiness-Security.md#rag-encryption-system) for complete implementation details, testing, and usage examples.

### Module Structure

**Location:** `Universal/AVA/Features/RAG/`

```
RAG/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ commonMain/kotlin/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/          # Domain models
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Document.kt
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chunk.kt
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SearchQuery.kt
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RAGRepository.kt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings/      # Embedding providers
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ EmbeddingProvider.kt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parser/          # Document parsers
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ DocumentParser.kt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ TextChunker.kt
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ TokenCounter.kt
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ androidMain/kotlin/
‚îÇ       ‚îú‚îÄ‚îÄ embeddings/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ONNXEmbeddingProvider.android.kt
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ AndroidModelDownloadManager.kt
‚îÇ       ‚îú‚îÄ‚îÄ parser/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ PdfParser.android.kt
‚îÇ       ‚îî‚îÄ‚îÄ data/
‚îÇ           ‚îú‚îÄ‚îÄ room/        # Database
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ RAGDatabase.kt
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ Entities.kt
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ Daos.kt
‚îÇ           ‚îú‚îÄ‚îÄ clustering/  # K-means
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ KMeansClustering.kt
‚îÇ           ‚îî‚îÄ‚îÄ SQLiteRAGRepository.kt
‚îÇ
‚îî‚îÄ‚îÄ build.gradle.kts
```

### Clean Architecture Layers

**Domain Layer (commonMain):**
- Pure Kotlin interfaces and models
- Platform-agnostic business logic
- No Android/iOS dependencies

**Data Layer (platformMain):**
- Platform-specific implementations
- ONNX Runtime (Android), CoreML (iOS)
- Room database (Android), SQLite.swift (iOS)

**Key Interfaces:**

```kotlin
// Domain: RAGRepository.kt
interface RAGRepository {
    suspend fun addDocument(request: AddDocumentRequest): Result<AddDocumentResult>
    suspend fun search(query: SearchQuery): Result<SearchResponse>
    suspend fun processDocuments(documentId: String? = null): Result<Int>
    fun listDocuments(status: DocumentStatus? = null): Flow<Document>
}

// Domain: EmbeddingProvider.kt
expect interface EmbeddingProvider {
    suspend fun embed(text: String): Result<Embedding.Float32>
    suspend fun embedBatch(texts: List<String>): Result<List<Embedding.Float32>>
}

// Android implementation
actual class ONNXEmbeddingProvider(context: Context) : EmbeddingProvider {
    // ONNX Runtime implementation
}
```

---

## 28.3 Document Ingestion Pipeline

### Pipeline Flow

```
PDF File ‚Üí Parse ‚Üí Chunk ‚Üí Embed ‚Üí Store ‚Üí Cluster
   ‚Üì         ‚Üì       ‚Üì       ‚Üì       ‚Üì        ‚Üì
  File   Metadata  512tok  384dim  SQLite  Assign
        +Pages    chunks  vectors  BLOB    to k-means
```

### 28.3.1 Document Parsing (6 Formats)

AVA's RAG system supports **6 document formats**, each optimized for different use cases:

#### Supported Formats Overview

| Format | Speed | Best For | Key Features |
|--------|-------|----------|--------------|
| **DOCX** | ‚ö° 10-20 pages/sec | Modern manuals, reports | Apache POI, heading extraction, tables |
| **TXT** | ‚ö° Instant | Logs, notes, plain text | Auto-section detection, UTF-8 |
| **HTML** | ‚ö° 20-50 pages/sec | **Web docs (URLs!)**, saved pages | Jsoup, content cleaning, metadata |
| **Markdown** | ‚ö° Instant | README files, GitHub docs | YAML front matter, code blocks |
| **RTF** | ‚ö° 5-10 pages/sec | Legacy Word docs | RTFEditorKit, structure preservation |
| **PDF** | üêå 2 pages/sec | Scanned manuals, legacy docs | PdfBox, OCR-compatible |

#### PDF Parser

**Library:** PdfBox-Android 2.0.27.0

```kotlin
class PdfParser(private val context: Context) : DocumentParser {
    init {
        PDFBoxResourceLoader.init(context)
    }

    override suspend fun parse(
        filePath: String,
        documentType: DocumentType
    ): Result<ParsedDocument> {
        val document = PDDocument.load(File(filePath))
        val textStripper = PDFTextStripper()

        val pages = mutableListOf<ParsedPage>()
        for (pageIndex in 0 until document.numberOfPages) {
            textStripper.startPage = pageIndex + 1
            textStripper.endPage = pageIndex + 1
            val pageText = textStripper.getText(document)

            pages.add(ParsedPage(
                pageNumber = pageIndex + 1,
                content = pageText,
                metadata = extractPageMetadata(document, pageIndex)
            ))
        }

        return Result.success(ParsedDocument(
            text = pages.joinToString("\n") { it.content },
            pages = pages,
            metadata = extractDocumentMetadata(document)
        ))
    }
}
```

**Features:**
- Full text extraction (not OCR)
- Page-by-page processing
- Metadata extraction (title, author, dates)
- ~2 pages/second performance

#### DOCX Parser (Fastest!)

**Library:** Apache POI 5.2.5

**Key Features:**
- **5-10x faster than PDF** (10-20 pages/sec vs 2 pages/sec)
- Extract heading styles (Heading1, Heading2, etc.)
- Handle tables and lists
- Extract document metadata

**Example:**
```kotlin
class DocxParser(private val context: Context) : DocumentParser {
    override suspend fun parse(filePath: String, documentType: DocumentType): Result<ParsedDocument> {
        val document = FileInputStream(file).use { XWPFDocument(it) }

        // Process paragraphs with heading detection
        document.paragraphs.forEach { paragraph ->
            val isHeading = paragraph.style?.startsWith("Heading") == true
            val headingLevel = extractHeadingLevel(paragraph.style)
            // ...
        }

        // Process tables
        document.tables.forEach { table ->
            textBuilder.append(extractTableText(table))
        }
    }
}
```

#### HTML Parser (Web Document Support!)

**Library:** Jsoup 1.17.1

**Key Features:**
- **Parse URLs directly** (https://developer.android.com/...)
- Clean ads, scripts, navigation, popups
- Auto-detect main content area
- Extract metadata (Open Graph, Twitter Cards)
- 15-second timeout for web requests

**Example:**
```kotlin
// Import from web URL
repository.addDocument(
    AddDocumentRequest(
        filePath = "https://developer.android.com/guide/components/activities",
        title = "Android Activities Guide",
        documentType = DocumentType.HTML
    )
)
```

**See:** `docs/Web-Document-Import-Guide.md` for complete guide

#### Other Parsers

**TXT Parser:**
- Auto-detect sections (ALL CAPS, numbered, markdown-style)
- Create pseudo-pages (50 lines each)
- UTF-8 encoding support

**Markdown Parser:**
- GitHub-flavored Markdown
- YAML front matter extraction
- Code block handling

**RTF Parser:**
- RTFEditorKit for conversion
- Structure preservation
- Legacy compatibility

### 28.3.2 Parallel Processing Pipeline

**NEW:** Parallel multi-stage processing for 50% speedup

**Architecture:**
```
Stage 1: Page Production (sequential)
         ‚Üì
Stage 2: Chunking (2 parallel workers)
         ‚Üì
Stage 3: Embedding (3 parallel workers, batched)
         ‚Üì
Stage 4: Storage (batched writes, 500 chunks)
```

**Performance Improvement:**
- 1000-page PDF: 10 minutes ‚Üí **4.5-5.5 minutes** (50% faster)
- Buffer sizes: 20 pages, 100 chunks
- Embedding batch size: 32 chunks
- Storage batch size: 500 chunks

**Example:**
```kotlin
class ParallelRAGProcessor(
    private val database: RAGDatabase,
    private val parser: DocumentParser,
    private val chunker: TextChunker,
    private val embeddingProvider: EmbeddingProvider
) {
    suspend fun processDocument(
        request: AddDocumentRequest,
        onProgress: (Float) -> Unit = {}
    ): Result<Int> = coroutineScope {
        val pagesChannel = Channel<PageChunk>(20)
        val chunksChannel = Channel<TextChunk>(100)
        val embeddingsChannel = Channel<EmbeddedChunk>(100)

        // Launch parallel workers for each stage
        // ...
    }
}
```

### 28.3.3 Text Chunking

**Strategy:** Hybrid semantic chunking

**Configuration:**
```kotlin
data class ChunkingConfig(
    val strategy: ChunkingStrategy = ChunkingStrategy.HYBRID,
    val maxTokens: Int = 512,            // Max chunk size
    val overlapTokens: Int = 50,         // Overlap between chunks
    val respectSectionBoundaries: Boolean = true,
    val minChunkTokens: Int = 100        // Min chunk size
)
```

**Algorithm:**
```kotlin
class TextChunker(private val config: ChunkingConfig) {
    fun chunk(document: Document, parsedDocument: ParsedDocument): List<Chunk> {
        when (config.strategy) {
            ChunkingStrategy.FIXED_SIZE -> chunkFixedSize()
            ChunkingStrategy.SEMANTIC -> chunkSemantic()
            ChunkingStrategy.HYBRID -> chunkHybrid()
        }
    }

    private fun chunkHybrid(...)  {
        // 1. Identify section boundaries (headings, paragraphs)
        // 2. Create chunks respecting boundaries
        // 3. Ensure chunks are 100-512 tokens
        // 4. Add 50-token overlap for context
    }
}
```

**Chunking Performance:**
- Speed: 1000 chunks/second
- Output: List<Chunk> with metadata

### 28.3.4 Embedding Generation

**Model:** all-MiniLM-L6-v2 (Sentence Transformers)

**Specifications:**
- Dimensions: 384
- Model size: 86MB
- Inference: ~50ms per chunk
- Batch size: 32 (optimal)

**Implementation:**
```kotlin
class ONNXEmbeddingProvider(
    private val context: Context,
    private val modelId: String = "all-MiniLM-L6-v2"
) : EmbeddingProvider {

    private val ortSession: OrtSession by lazy {
        loadModelFromExternalStorage()
    }

    override suspend fun embedBatch(
        texts: List<String>
    ): Result<List<Embedding.Float32>> {
        val tokenized = texts.map { tokenize(it) }
        val inputTensor = createInputTensor(tokenized)

        val outputs = ortSession.run(mapOf("input" to inputTensor))
        val embeddings = outputs[0].floatBuffer

        return Result.success(
            texts.mapIndexed { i, _ ->
                Embedding.Float32(
                    embeddings.slice(i * 384, (i + 1) * 384).toFloatArray()
                )
            }
        )
    }
}
```

**Model Location:**
```
External: /sdcard/Android/data/com.augmentalis.ava/files/models/all-MiniLM-L6-v2.onnx
Bundled:  assets/models/ (optional, increases APK size)
```

### 28.3.5 Storage

**Database:** Room (SQLite wrapper)

**Schema (Version 2):**
```sql
CREATE TABLE documents (
    id TEXT PRIMARY KEY,
    title TEXT,
    file_path TEXT UNIQUE,
    document_type TEXT,
    total_pages INTEGER,
    added_timestamp TEXT,
    last_accessed_timestamp TEXT,
    metadata_json TEXT
);

CREATE TABLE chunks (
    id TEXT PRIMARY KEY,
    document_id TEXT,
    chunk_index INTEGER,
    content TEXT,
    token_count INTEGER,
    embedding_blob BLOB,         -- 1536 bytes (384 * 4)
    embedding_type TEXT,          -- "float32"
    embedding_dimension INTEGER,
    cluster_id TEXT,              -- Phase 3.2
    distance_to_centroid REAL,    -- Phase 3.2
    FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE
);

CREATE TABLE clusters (
    id TEXT PRIMARY KEY,
    centroid_blob BLOB,          -- 1536 bytes
    embedding_dimension INTEGER,
    chunk_count INTEGER,
    created_timestamp TEXT,
    last_updated_timestamp TEXT
);
```

**Storage Size:**
- Per chunk: ~2.2 KB
- 10k chunks: ~22 MB
- 200k chunks: ~440 MB

---

## 28.4 Vector Search Implementation

### 28.4.1 Linear Search (Phase 3.1)

**Algorithm:**
```kotlin
private suspend fun searchLinear(
    queryEmbedding: FloatArray,
    query: SearchQuery
): List<Triple<ChunkEntity, Float, Embedding.Float32>> {
    val allChunks = chunkDao.getAllChunks()

    return allChunks
        .map { chunk ->
            val embedding = deserializeEmbedding(chunk)
            val similarity = cosineSimilarity(queryEmbedding, embedding.values)
            Triple(chunk, similarity, embedding)
        }
        .filter { (_, similarity, _) -> similarity >= query.minSimilarity }
        .sortedByDescending { (_, similarity, _) -> similarity }
        .take(query.maxResults)
}
```

**Cosine Similarity:**
```kotlin
private fun cosineSimilarity(vec1: FloatArray, vec2: FloatArray): Float {
    var dotProduct = 0f
    var norm1 = 0f
    var norm2 = 0f

    for (i in vec1.indices) {
        dotProduct += vec1[i] * vec2[i]
        norm1 += vec1[i] * vec1[i]
        norm2 += vec2[i] * vec2[i]
    }

    return dotProduct / sqrt(norm1 * norm2)
}
```

**Performance:**
- 1k chunks: ~5ms
- 10k chunks: ~50ms
- 100k chunks: ~500ms
- 200k chunks: ~1000ms

### 28.4.2 Clustered Search (Phase 3.2)

**Two-Stage Algorithm:**

**Stage 1: Find Nearest Clusters**
```kotlin
// Find top-3 nearest clusters to query
val nearestClusters = clusterDao.getAllClusters()
    .map { cluster ->
        val centroid = deserializeCentroid(cluster)
        val distance = euclideanDistance(queryEmbedding, centroid)
        cluster.id to distance
    }
    .sortedBy { (_, distance) -> distance }
    .take(3)  // Top-3 clusters
    .map { (clusterId, _) -> clusterId }
```

**Stage 2: Search Chunks in Clusters**
```kotlin
// Search only chunks in top-3 clusters
val candidateChunks = nearestClusters.flatMap { clusterId ->
    chunkDao.getChunksByCluster(clusterId)
}

return candidateChunks
    .map { chunk ->
        val similarity = cosineSimilarity(queryEmbedding, chunk.embedding)
        Triple(chunk, similarity, embedding)
    }
    .filter { (_, similarity, _) -> similarity >= query.minSimilarity }
    .sortedByDescending { (_, similarity, _) -> similarity }
    .take(query.maxResults)
```

**Performance:**
- 200k chunks: **<50ms (40x faster than linear)**
- Stage 1: ~1ms (256 clusters)
- Stage 2: ~5ms (~2,340 chunks)

---

## 28.5 Performance Optimization (K-means Clustering)

### 28.5.1 K-means Algorithm

**Purpose:** Group similar embeddings into clusters for fast approximate search

**Configuration:**
```kotlin
class KMeansClustering(
    private val k: Int = 256,                    // Number of clusters
    private val maxIterations: Int = 50,
    private val convergenceThreshold: Float = 0.001f
)
```

**Algorithm Flow:**
```
1. Initialize 256 centroids using k-means++
2. Assign each chunk to nearest centroid
3. Recompute centroids as mean of assigned chunks
4. Repeat until convergence (<0.1% improvement)
5. Store centroids in clusters table
6. Update chunks with cluster_id
```

**K-means++ Initialization:**
```kotlin
private fun initializeCentroidsKMeansPlusPlus(
    vectors: List<FloatArray>,
    dimension: Int
): Array<FloatArray> {
    val centroids = Array(k) { FloatArray(dimension) }

    // 1. Choose first centroid randomly
    centroids[0] = vectors[random.nextInt(vectors.size)]

    // 2. For each subsequent centroid:
    for (i in 1 until k) {
        // Choose with probability proportional to squared distance
        val distances = vectors.map { v ->
            centroids.take(i).minOf { c -> euclideanDistance(v, c) }.pow(2)
        }
        val totalDistance = distances.sum()

        var target = random.nextFloat() * totalDistance
        for (j in vectors.indices) {
            target -= distances[j]
            if (target <= 0) {
                centroids[i] = vectors[j]
                break
            }
        }
    }

    return centroids
}
```

**Benefits of K-means++:**
- 30-50% faster convergence
- Better final cluster quality
- Fewer iterations needed

### 28.5.2 Cluster Rebuild

**When to Rebuild:**
- Initial setup (after 1000+ chunks)
- After bulk document imports
- When chunk count increases >20%
- Periodic maintenance (weekly/monthly)

**Rebuild Process:**
```kotlin
suspend fun rebuildClusters(): Result<ClusteringStats> {
    // 1. Get all chunk embeddings
    val chunks = chunkDao.getAllChunks()
    val embeddings = chunks.map { deserializeEmbedding(it).values }

    // 2. Run k-means clustering
    val result = kMeans.cluster(embeddings)

    // 3. Delete old clusters
    clusterDao.deleteAllClusters()

    // 4. Save new clusters
    val clusterEntities = result.centroids.mapIndexed { i, centroid ->
        ClusterEntity(
            id = "cluster_$i",
            centroid_blob = serializeCentroid(centroid),
            chunk_count = result.clusterSizes[i],
            ...
        )
    }
    clusterDao.insertClusters(clusterEntities)

    // 5. Assign chunks to clusters
    chunks.forEachIndexed { i, chunk ->
        val clusterId = "cluster_${result.assignments[i]}"
        chunkDao.updateClusterAssignment(chunk.id, clusterId, ...)
    }

    return ClusteringStats(...)
}
```

**Performance:**
- 10k chunks: ~5 seconds
- 100k chunks: ~30 seconds
- 200k chunks: ~60 seconds

---

## 28.6 Model Management

### 28.6.1 External Model Loading

**Model Location:**
```
/sdcard/Android/data/com.augmentalis.ava/files/models/
‚îú‚îÄ‚îÄ all-MiniLM-L6-v2.onnx    (86 MB)
‚îî‚îÄ‚îÄ llm/
    ‚îî‚îÄ‚îÄ gemma-2b-it/          (2 GB)
```

**Download Instructions:**
```bash
# 1. Download ONNX model
curl -L https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/onnx/model.onnx \
  -o all-MiniLM-L6-v2.onnx

# 2. Push to device
adb push all-MiniLM-L6-v2.onnx /sdcard/Android/data/com.augmentalis.ava/files/models/

# 3. Verify
adb shell ls -lh /sdcard/Android/data/com.augmentalis.ava/files/models/
```

**Loading Priority:**
1. External storage (primary)
2. Provided modelPath parameter
3. Downloaded models (ModelDownloadManager)
4. Bundled assets (fallback)

**Benefits:**
- Small APK size (~30MB)
- User can update models
- Platform-agnostic (AOSP, Google Play)
- Hidden from media scanners (.nomedia)

### 28.6.2 Platform Detection

**AOSP vs Google Play:**
```kotlin
object PlatformDetector {
    fun getPlatform(context: Context): Platform {
        val hasGooglePlay = isGooglePlayServicesAvailable(context)
        val installer = context.packageManager.getInstallerPackageName(context.packageName)

        return when {
            hasGooglePlay && installer == "com.android.vending" -> Platform.GOOGLE_PLAY
            installer == "org.fdroid.fdroid" -> Platform.FDROID
            else -> Platform.AOSP
        }
    }
}
```

**Model Download Strategy:**
- **AOSP/F-Droid:** Download from HuggingFace or custom server
- **Google Play:** Future support for Dynamic Feature Modules

### 28.6.3 Multilingual Models

AVA's RAG system supports **50+ languages** through multilingual embedding models.

**Supported Languages:**
- European: English, French, German, Spanish, Italian, Portuguese, Dutch, Polish, Russian, Turkish, and more
- Asian: Chinese, Japanese, Korean, Arabic, Hebrew, Thai, Vietnamese, Indonesian, Hindi
- And 30+ additional languages

**Model Options:**

| Model ID | Languages | Size | Dimensions | Use Case |
|----------|-----------|------|------------|----------|
| AVA-ONX-384-MULTI | 50+ | 470 MB | 384 | General multilingual (recommended) |
| AVA-ONX-768-MULTI | 50+ | 1.1 GB | 768 | High-quality multilingual |
| AVA-ONX-512-MULTI | 15 | 540 MB | 512 | Major languages only |
| AVA-ONX-384-ZH | Chinese | 400 MB | 384 | Chinese-only collections |
| AVA-ONX-768-JA | Japanese | 450 MB | 768 | Japanese-only collections |

**Usage:**
```kotlin
// Use multilingual model
val embeddingProvider = ONNXEmbeddingProvider(
    context = context,
    modelId = "AVA-ONX-384-MULTI"  // Supports 50+ languages
)

val repository = SQLiteRAGRepository(
    context = context,
    embeddingProvider = embeddingProvider,
    enableClustering = true
)

// Add documents in different languages
repository.addDocument(AddDocumentRequest(
    filePath = "/path/to/english-manual.pdf",
    title = "English Manual",
    metadata = mapOf("language" to "en")
))

repository.addDocument(AddDocumentRequest(
    filePath = "/path/to/‰∏≠ÊñáÊâãÂÜå.pdf",
    title = "Chinese Manual",
    metadata = mapOf("language" to "zh")
))

// Search works across all languages
val results = repository.search("user guide", topK = 5)
// Returns relevant results from both English and Chinese documents
```

**Cross-Lingual Search:**
```kotlin
// Query in English, find results in Chinese/Japanese/etc.
val query = "how to reset device"
val results = repository.search(query, topK = 5)

// Multilingual model finds semantically similar content
// regardless of query language
```

**Download Multilingual Models:**
```bash
# Recommended: Multilingual MiniLM-L12 (470 MB)
curl -L https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/onnx/model.onnx \
  -o AVA-ONX-384-MULTI.onnx

# Push to device
adb push AVA-ONX-384-MULTI.onnx /sdcard/Android/data/com.augmentalis.ava/files/models/
```

**See Also:** `docs/MULTILINGUAL-RAG-SETUP.md` for complete multilingual guide

### 28.6.4 Model Quantization

**Quantization** reduces model file sizes by 50-75% with minimal quality loss.

**What is Quantization?**
- Converts 32-bit floats ‚Üí 8-bit or 16-bit integers
- Reduces storage requirements dramatically
- Faster inference (INT8 ops are faster than FP32)
- 95-98% of original accuracy retained

**Quantization Modes:**

| Mode | Size Reduction | Quality Loss | Speed | Use Case |
|------|----------------|--------------|-------|----------|
| INT8 | 75% | ~3-5% | Faster | Recommended for most users |
| FP16 | 50% | ~1-2% | Similar | When highest quality needed |

**Size Comparisons:**

| Model | Original | INT8 | FP16 |
|-------|----------|------|------|
| AVA-ONX-384-BASE | 86 MB | 22 MB | 43 MB |
| AVA-ONX-384-MULTI | 470 MB | 117 MB | 235 MB |
| AVA-ONX-768-QUAL | 420 MB | 105 MB | 210 MB |

**Creating Quantized Models:**

```bash
# Install quantization tool
pip install onnxruntime

# Download original model
curl -L https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/onnx/model.onnx \
  -o AVA-ONX-384-MULTI.onnx

# Quantize to INT8 (75% smaller, recommended)
python3 scripts/quantize-models.py \
  AVA-ONX-384-MULTI.onnx \
  AVA-ONX-384-MULTI-INT8.onnx \
  int8

# Output:
# Original size: 470.00 MB
# Quantized size: 117.50 MB
# Size reduction: 75.0%

# Push quantized model to device
adb push AVA-ONX-384-MULTI-INT8.onnx /sdcard/Android/data/com.augmentalis.ava/files/models/
```

**Using Quantized Models:**
```kotlin
// No code changes needed! Just change the modelId
val embeddingProvider = ONNXEmbeddingProvider(
    context = context,
    modelId = "AVA-ONX-384-MULTI-INT8"  // Quantized model
)

// Everything works exactly the same
// - Same dimension (384)
// - Same search quality (95%+ of original)
// - 75% less storage
// - Faster inference
```

**Batch Quantization:**
```bash
# Quantize multiple models at once
./scripts/quantize-all-models.sh models/ int8

# Processes all .onnx files in directory
# Skips already-quantized models
```

**See Also:** `docs/MODEL-QUANTIZATION-GUIDE.md` for complete quantization guide

### 28.6.5 Model Registry

AVA uses a **proprietary naming convention** for all models to obscure origins and simplify management.

**Naming Format:** `AVA-{MODEL}-{PARAMS}-{QUANT}.{ext}`

**Example Mappings:**

| AVA Filename | Original Model | Size | Purpose |
|--------------|----------------|------|---------|
| AVA-ONX-384-BASE.onnx | all-MiniLM-L6-v2 | 86 MB | English embeddings |
| AVA-ONX-384-MULTI.onnx | paraphrase-multilingual-MiniLM-L12-v2 | 470 MB | Multilingual embeddings |
| AVA-ONX-384-MULTI-INT8.onnx | paraphrase-multilingual-MiniLM-L12-v2 (quantized) | 117 MB | Multilingual (75% smaller) |
| AVA-GEM-2B-Q4.tar | gemma-2b-it-q4f16_1-android | ~2 GB | LLM chat |

**Model ID Mapping in Code:**
```kotlin
// ONNXEmbeddingProvider.android.kt
private val modelIdMap = mapOf(
    // English models
    "AVA-ONX-384-BASE" to "all-MiniLM-L6-v2",
    "AVA-ONX-384-FAST" to "paraphrase-MiniLM-L3-v2",
    "AVA-ONX-768-QUAL" to "all-mpnet-base-v2",

    // Multilingual models
    "AVA-ONX-384-MULTI" to "paraphrase-multilingual-MiniLM-L12-v2",
    "AVA-ONX-768-MULTI" to "paraphrase-multilingual-mpnet-base-v2",

    // Quantized models
    "AVA-ONX-384-BASE-INT8" to "all-MiniLM-L6-v2",
    "AVA-ONX-384-MULTI-INT8" to "paraphrase-multilingual-MiniLM-L12-v2",

    // Language-specific
    "AVA-ONX-384-ZH" to "sbert-chinese-general-v2",
    "AVA-ONX-768-JA" to "sentence-bert-base-ja-mean-tokens-v2"
)
```

**Backward Compatibility:**
```kotlin
// System checks for proprietary name first, falls back to original
private fun loadModelFromAssets(): File {
    val externalModelsDir = File(context.getExternalFilesDir(null), "models")

    // 1. Try proprietary filename (AVA-ONX-384-BASE.onnx)
    val avaModelFile = File(externalModelsDir, "$modelId.onnx")
    if (avaModelFile.exists()) return avaModelFile

    // 2. Fall back to original filename (all-MiniLM-L6-v2.onnx)
    val originalModelId = modelIdMap[modelId] ?: modelId
    val originalModelFile = File(externalModelsDir, "$originalModelId.onnx")
    if (originalModelFile.exists()) return originalModelFile

    // 3. Error if not found
    throw FileNotFoundException("Model not found: $modelId")
}
```

**See Also:** `docs/AVA-MODEL-NAMING-REGISTRY.md` for complete registry

---

## 28.7 Usage and Integration

### 28.7.1 Basic Usage

```kotlin
// 1. Initialize repository
val repository = SQLiteRAGRepository(
    context = context,
    embeddingProvider = ONNXEmbeddingProvider(context),
    enableClustering = true,
    clusterCount = 256,
    topClusters = 3
)

// 2. Add documents
val result = repository.addDocument(
    AddDocumentRequest(
        filePath = "/path/to/manual.pdf",
        title = "User Manual",
        processImmediately = true
    )
)

// 3. Rebuild clusters (after bulk import)
val stats = repository.rebuildClusters().getOrThrow()
println("Clustered ${stats.chunkCount} chunks in ${stats.timeMs}ms")

// 4. Search
val searchResults = repository.search(
    SearchQuery(
        query = "How do I configure the device?",
        maxResults = 5,
        minSimilarity = 0.7f
    )
).getOrThrow()

// 5. Display results
searchResults.results.forEach { result ->
    println("Similarity: ${result.similarity}")
    println("Content: ${result.chunk.content}")
    println("Document: ${result.document?.title}")
    println("---")
}
```

### 28.7.2 ViewModel Integration

```kotlin
class DocumentViewModel(
    private val ragRepository: RAGRepository
) : ViewModel() {

    private val _documents = MutableStateFlow<List<Document>>(emptyList())
    val documents: StateFlow<List<Document>> = _documents.asStateFlow()

    private val _searchResults = MutableStateFlow<List<SearchResult>>(emptyList())
    val searchResults: StateFlow<List<SearchResult>> = _searchResults.asStateFlow()

    fun loadDocuments() {
        viewModelScope.launch {
            ragRepository.listDocuments().collect { document ->
                _documents.value = _documents.value + document
            }
        }
    }

    fun search(query: String) {
        viewModelScope.launch {
            val result = ragRepository.search(
                SearchQuery(query = query, maxResults = 10)
            )
            _searchResults.value = result.getOrNull()?.results ?: emptyList()
        }
    }

    fun addDocument(uri: Uri) {
        viewModelScope.launch {
            val filePath = getFilePathFromUri(uri)
            ragRepository.addDocument(
                AddDocumentRequest(filePath = filePath, processImmediately = true)
            )
        }
    }
}
```

### 28.7.3 Compose UI

```kotlin
@Composable
fun DocumentSearchScreen(viewModel: DocumentViewModel) {
    var query by remember { mutableStateOf("") }
    val searchResults by viewModel.searchResults.collectAsState()

    Column(modifier = Modifier.fillMaxSize().padding(16.dp)) {
        // Search bar
        OutlinedTextField(
            value = query,
            onValueChange = { query = it },
            label = { Text("Search documents") },
            modifier = Modifier.fillMaxWidth(),
            trailingIcon = {
                IconButton(onClick = { viewModel.search(query) }) {
                    Icon(Icons.Default.Search, "Search")
                }
            }
        )

        Spacer(modifier = Modifier.height(16.dp))

        // Results
        LazyColumn {
            items(searchResults) { result ->
                SearchResultCard(result)
            }
        }
    }
}

@Composable
fun SearchResultCard(result: SearchResult) {
    Card(modifier = Modifier.fillMaxWidth().padding(vertical = 8.dp)) {
        Column(modifier = Modifier.padding(16.dp)) {
            Text(
                text = result.document?.title ?: "Unknown",
                style = MaterialTheme.typography.titleMedium
            )
            Text(
                text = "Similarity: ${(result.similarity * 100).toInt()}%",
                style = MaterialTheme.typography.bodySmall,
                color = MaterialTheme.colorScheme.secondary
            )
            Spacer(modifier = Modifier.height(8.dp))
            Text(
                text = result.chunk.content,
                style = MaterialTheme.typography.bodyMedium,
                maxLines = 3,
                overflow = TextOverflow.Ellipsis
            )
        }
    }
}
```

### 28.7.4 RAGChatEngine (LLM Integration)

**NEW:** Ready-to-use RAG+LLM chat engine

**Purpose:** Combines document retrieval with LLM generation for context-aware responses

**Flow:**
```
Question ‚Üí Search Docs ‚Üí Assemble Context ‚Üí LLM Generate ‚Üí Stream Response + Sources
```

**Example Usage:**
```kotlin
// 1. Create chat engine
val chatEngine = RAGChatEngine(
    ragRepository = repository,
    llmProvider = MLCLLMProvider(context), // Implement this with MLC-LLM
    config = ChatConfig(
        maxContextChunks = 5,      // Top 5 chunks
        minSimilarity = 0.7f,       // 70% minimum match
        maxContextLength = 2000     // ~500 tokens
    )
)

// 2. Ask questions
lifecycleScope.launch {
    chatEngine.ask("How do I reset the device?").collect { response ->
        when (response) {
            is ChatResponse.Streaming -> {
                // Update UI with text chunk
                appendText(response.text)
            }
            is ChatResponse.Complete -> {
                // Show sources
                displaySources(response.sources)
            }
            is ChatResponse.NoContext -> {
                // No relevant documents
                showMessage(response.message)
            }
            is ChatResponse.Error -> {
                // Handle error
                showError(response.message)
            }
        }
    }
}
```

**Key Features:**
- Streaming responses (token-by-token)
- Source citations (document title, page number, similarity score)
- Conversation history support
- No-context detection
- Configurable chunk selection

**LLMProvider Interface:**
```kotlin
interface LLMProvider {
    fun generateStream(prompt: String): Flow<String>
    suspend fun generate(prompt: String): String
}

// Implement with MLC-LLM:
class MLCLLMProvider(private val context: Context) : LLMProvider {
    override fun generateStream(prompt: String): Flow<String> = flow {
        // Use MLC-LLM's Gemma-2b-it model
        // Emit tokens as they're generated
    }
}
```

**Prompt Template:**
```
You are AVA, an intelligent assistant with access to technical documentation and manuals.
Your role is to help users find information from their documents accurately and efficiently.

Context from documents:
[Source: User Manual, Page 42, Relevance: 95%]
To reset the device, press and hold the power button for 10 seconds...

[Source: User Manual, Page 58, Relevance: 87%]
If the device freezes, perform a hard reset by...

User question: How do I reset the device?

Instructions:
- Answer based ONLY on the provided context
- Cite specific sources (document name, page number)
- If the context doesn't contain the answer, say "I don't have that information in the documents"
- Be conversational but accurate
- Keep responses concise unless detail is requested

Answer:
```

**Configuration:**
```kotlin
data class ChatConfig(
    val maxContextChunks: Int = 5,
    val minSimilarity: Float = 0.7f,
    val maxContextLength: Int = 2000,
    val maxHistoryMessages: Int = 10,
    val systemPrompt: String = "You are AVA, an intelligent assistant..."
)
```

### 28.7.5 Model Selection via Settings UI

**NEW:** In-app model selection with detailed guidance (Added: 2025-11-06)

AVA now includes a developer settings UI for selecting and configuring ONNX embedding models directly within the app. This provides users with an easy way to switch between models based on their needs (language support, file size, quality).

**Location:** Settings ‚Üí Developer Settings ‚Üí RAG Embedding Model

**Features:**
- ‚úÖ **Model Selection Dropdown** - Choose from 6 available models
- ‚úÖ **Model Information Dialog** - Detailed specs, download instructions, quality metrics
- ‚úÖ **Persistent Storage** - Selection saved using DataStore
- ‚úÖ **Smart Defaults** - Recommends AVA-ONX-384-BASE-INT8 (22 MB)
- ‚úÖ **Guidance Text** - Each model shows size, languages, quality rating

**Available Models:**

| Model | Languages | Size | Quality | Use Case |
|-------|-----------|------|---------|----------|
| **AVA-ONX-384-BASE-INT8 ‚≠ê** | English | 22 MB | High (95%) | **Recommended** - Best balance |
| AVA-ONX-384-MULTI-INT8 | 50+ languages | 117 MB | High (95%) | Multilingual documents |
| AVA-ONX-384-FAST-INT8 | English | 15 MB | Medium (85%) | Memory-constrained devices |
| AVA-ONX-768-QUAL-INT8 | English | 105 MB | Very High (98%) | Production quality |
| AVA-ONX-384-BASE | English | 86 MB | Very High (100%) | Unquantized original |
| AVA-ONX-384-MULTI | 50+ languages | 470 MB | Very High (100%) | Unquantized multilingual |

**Usage in Code:**

```kotlin
// Settings UI automatically updates DataStore preference
// Reading selected model from settings:
val settingsViewModel = SettingsViewModel(context)
val selectedModelId = settingsViewModel.getEmbeddingModel()  // e.g., "AVA-ONX-384-BASE-INT8"

// Using factory with model ID:
val embeddingProvider = EmbeddingProviderFactory.getONNXProviderWithModelId(
    modelId = selectedModelId
)

// Or let factory use default from settings:
val embeddingProvider = EmbeddingProviderFactory.getONNXProviderWithModelId()
```

**UI Implementation:**

The settings UI is implemented using Jetpack Compose with Material 3 components:

```kotlin
// SettingsScreen.kt - Developer Settings section
item {
    SettingsSectionHeader("Developer Settings")
}

item {
    ModelSelectionSettingItem(
        title = "RAG Embedding Model",
        selectedModel = uiState.selectedEmbeddingModel,
        onModelSelected = { viewModel.setEmbeddingModel(it) },
        onShowModelInfo = { viewModel.showModelInfo(it) },
        icon = Icons.Default.Memory
    )
}

// Model info dialog shows:
// - Model ID, Languages, File Size, Dimensions, Quality
// - Description and recommended use cases
// - Complete download and installation instructions
if (uiState.showModelInfoDialog && uiState.modelInfoToShow != null) {
    ModelInfoDialog(
        modelInfo = uiState.modelInfoToShow,
        onDismiss = { viewModel.dismissModelInfoDialog() }
    )
}
```

**DataStore Integration:**

Model selection is persisted using DataStore Preferences:

```kotlin
// SettingsViewModel.kt
private object PreferencesKeys {
    val EMBEDDING_MODEL = stringPreferencesKey("embedding_model")
}

fun setEmbeddingModel(modelId: String) {
    viewModelScope.launch {
        context.dataStore.edit { preferences ->
            preferences[PreferencesKeys.EMBEDDING_MODEL] = modelId
        }
    }
}

suspend fun getEmbeddingModel(): String {
    return context.dataStore.data.first()[PreferencesKeys.EMBEDDING_MODEL]
        ?: "AVA-ONX-384-BASE-INT8"  // Default
}
```

**Model Information Dialog:**

Each model has a detailed info dialog accessible via the (i) icon in the dropdown:

**Dialog Contents:**
- **Model ID:** `AVA-ONX-384-BASE-INT8`
- **Languages:** English
- **File Size:** 22 MB
- **Dimensions:** 384
- **Quality:** High (95%)
- **Description:** Full description of model characteristics, quantization details, recommended use cases
- **Download Instructions:** Complete step-by-step curl/adb commands with proper model naming

**Example Dialog for AVA-ONX-384-MULTI-INT8:**

```
Multilingual (INT8)

Model ID:       AVA-ONX-384-MULTI-INT8
Languages:      50+ languages
File Size:      117 MB
Dimensions:     384
Quality:        High (95%)

Description:
Supports 50+ languages including English, Spanish, French, German, Chinese,
Japanese, Arabic, Hindi, and more. Enables cross-lingual search (query in one
language, find results in another). Quantized for 75% size reduction.

Download Instructions:
1. Download: curl -L https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/onnx/model.onnx -o model.onnx
2. Quantize: python3 scripts/required/quantize-models.py model.onnx AVA-ONX-384-MULTI-INT8.onnx int8
3. Push: adb push AVA-ONX-384-MULTI-INT8.onnx /sdcard/Android/data/com.augmentalis.ava/files/models/
```

**Benefits:**

1. **User-Friendly:** No need to edit code or recompile to switch models
2. **Informed Choice:** Detailed model information helps users make the right decision
3. **Complete Guidance:** Download and installation instructions included
4. **Persistent:** Selection survives app restarts
5. **Smart Defaults:** Recommends optimal model (AVA-ONX-384-BASE-INT8)

**Testing Model Selection:**

```kotlin
// 1. Open Settings ‚Üí Developer Settings
// 2. Tap "RAG Embedding Model"
// 3. See current selection and available models
// 4. Tap (i) icon to view model details
// 5. Select new model
// 6. Selection is saved automatically
// 7. Restart RAG repository to use new model

// Programmatic testing:
@Test
fun testModelSelection() = runTest {
    val viewModel = SettingsViewModel(context)

    // Set model
    viewModel.setEmbeddingModel("AVA-ONX-384-MULTI-INT8")

    // Verify persistence
    val selectedModel = viewModel.getEmbeddingModel()
    assertEquals("AVA-ONX-384-MULTI-INT8", selectedModel)
}
```

**Files Modified:**
- `apps/ava-standalone/src/main/kotlin/com/augmentalis/ava/ui/settings/SettingsScreen.kt` - UI components
- `apps/ava-standalone/src/main/kotlin/com/augmentalis/ava/ui/settings/SettingsViewModel.kt` - State management
- `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/embeddings/EmbeddingProviderFactory.android.kt` - Model ID support

**See Also:**
- Section 28.6.3: Multilingual Models
- Section 28.6.4: Model Quantization
- Section 28.6.5: Model Registry
- `docs/AVA-MODEL-NAMING-REGISTRY.md` - Complete model mapping
- `docs/DEVICE-MODEL-SETUP-COMPLETE.md` - Model installation guide

### 28.7.6 Bundled Model & Automatic Language Detection

**NEW:** Instant English support with bundled model + automatic multilingual suggestion (Added: 2025-11-06)

AVA now bundles the INT8-quantized English model directly in the APK for instant use, with automatic language detection that suggests downloading the multilingual model for non-English users.

**Key Features:**
- ‚úÖ **Bundled English Model** - AVA-ONX-384-BASE-INT8 (22 MB) included in APK
- ‚úÖ **Instant Availability** - No internet required for English documents
- ‚úÖ **Auto Language Detection** - Detects device language on startup
- ‚úÖ **Smart Recommendations** - Suggests multilingual model (113 MB) for non-English users
- ‚úÖ **One-Click Download** - Download button in Settings for recommended model

**Bundled Model Details:**

| Property | Value |
|----------|-------|
| **Model ID** | AVA-ONX-384-BASE-INT8 |
| **Location** | `apps/ava-standalone/src/main/assets/models/` |
| **File Size** | 22 MB (included in APK) |
| **Languages** | English only |
| **Quality** | High (95% - 3-5% loss from quantization) |
| **Availability** | Instant (no download needed) |
| **APK Impact** | +22 MB to APK size |

**Model Loading Priority (Updated):**

1. **Bundled Assets** (PRIMARY)
   - Checked first for instant use
   - AVA-ONX-384-BASE-INT8 always available
   - Extracted to cache on first use

2. **External Storage** (downloaded or user-placed)
   - `/sdcard/Android/data/{package}/files/models/`
   - AVA-ONX-384-MULTI-INT8 for multilingual
   - Overrides bundled model if present

3. **Provided modelPath** (absolute path)
   - For custom model locations

4. **ModelDownloadManager** (downloaded models)
   - Manages MULTI model downloads

**Automatic Language Detection:**

The app detects device language on startup and recommends the appropriate model:

```kotlin
// SettingsViewModel.kt
private fun getDeviceLanguage(): String {
    return java.util.Locale.getDefault().language
}

private fun getRecommendedModelForLanguage(): String {
    val language = getDeviceLanguage()
    return when (language) {
        "en" -> "AVA-ONX-384-BASE-INT8"  // Bundled, instant use
        "zh" -> "AVA-ONX-384-MULTI-INT8" // Chinese
        "ja" -> "AVA-ONX-384-MULTI-INT8" // Japanese
        "ko" -> "AVA-ONX-384-MULTI-INT8" // Korean
        "hi" -> "AVA-ONX-384-MULTI-INT8" // Hindi
        "ru" -> "AVA-ONX-384-MULTI-INT8" // Russian
        "ar" -> "AVA-ONX-384-MULTI-INT8" // Arabic
        "es", "fr", "de", "it", "pt" -> "AVA-ONX-384-MULTI-INT8" // Romance
        else -> "AVA-ONX-384-MULTI-INT8" // Default multilingual
    }
}
```

**Language Recommendation Banner:**

When device language is not English, a prominent banner appears in Settings:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üåê  Multilingual Model Recommended                  ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Device language: Spanish (Espa√±ol).                 ‚îÇ
‚îÇ  Download multilingual model (113 MB) for better     ‚îÇ
‚îÇ  results in your language.                           ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ                                      [Download] ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**User Experience Flow:**

**English User (Default):**
1. Install app
2. Model loads instantly (bundled)
3. Start using RAG immediately
4. No internet required

**Non-English User (e.g., Spanish):**
1. Install app
2. Open app ‚Üí English model works but not optimal
3. Navigate to Settings
4. See banner: "Multilingual Model Recommended - Device language: Spanish"
5. Tap "Download" button
6. Model downloads (113 MB)
7. Automatically switches to multilingual model
8. Better results in Spanish

**Code Example - Using Bundled Model:**

```kotlin
// Default initialization - uses bundled model automatically
val embeddingProvider = EmbeddingProviderFactory.getONNXProviderWithModelId()
// Returns AVA-ONX-384-BASE-INT8 from assets

// Check if model is available (always true for bundled model)
val isAvailable = embeddingProvider.isAvailable()
// Returns: true (instant)

// Generate embeddings immediately
val result = embeddingProvider.embed("How do I reset the device?")
// Works instantly, no download needed
```

**Code Example - Detecting and Downloading Multilingual:**

```kotlin
// Check if multilingual is recommended
val settingsViewModel = SettingsViewModel(context)
val shouldSuggestMulti = settingsViewModel.shouldSuggestMultilingualDownload()

if (shouldSuggestMulti) {
    // User sees banner with download button
    // On click:
    val downloadManager = AndroidModelDownloadManager(context)

    downloadManager.downloadModel(
        modelId = "AVA-ONX-384-MULTI",
        onProgress = { progress ->
            // Update UI: "Downloading... ${(progress * 100).toInt()}%"
        }
    )

    // After download completes:
    settingsViewModel.setEmbeddingModel("AVA-ONX-384-MULTI-INT8")

    // Recreate provider with new model
    val multilingualProvider = EmbeddingProviderFactory.getONNXProviderWithModelId(
        modelId = "AVA-ONX-384-MULTI-INT8"
    )
}
```

**Benefits:**

1. **Zero Download Time** for English users (most common)
2. **Instant App Usability** - works immediately after install
3. **Small APK Size** - Only 22 MB added vs 113 MB for multilingual
4. **Automatic Optimization** - Right model for right language
5. **Progressive Enhancement** - English works, multilingual optional

**Supported Languages with Auto-Detection:**

| Language | Code | Recommendation | Download Size |
|----------|------|----------------|---------------|
| English | en | AVA-ONX-384-BASE-INT8 (bundled) | 0 MB (included) |
| Chinese | zh | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Japanese | ja | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Korean | ko | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Hindi | hi | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Russian | ru | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Arabic | ar | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Spanish | es | AVA-ONX-384-MULTI-INT8 | 113 MB |
| French | fr | AVA-ONX-384-MULTI-INT8 | 113 MB |
| German | de | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Italian | it | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Portuguese | pt | AVA-ONX-384-MULTI-INT8 | 113 MB |
| Others | * | AVA-ONX-384-MULTI-INT8 | 113 MB |

**APK Size Comparison:**

| Approach | APK Size | English Ready | Multilingual Ready |
|----------|----------|---------------|-------------------|
| **Current (Bundled BASE)** | ~52 MB | ‚úÖ Instant | ‚è¨ Download (113 MB) |
| No Model Bundled | ~30 MB | ‚è¨ Download (22 MB) | ‚è¨ Download (113 MB) |
| Bundle MULTI | ~143 MB | ‚úÖ Instant | ‚úÖ Instant |

**Why Bundle BASE-INT8?**
- 73% of users speak English as primary or secondary language
- Instant functionality for majority of users
- Small size (22 MB) vs MULTI (113 MB)
- Non-English users can download MULTI when needed

**Model Repository Location:**

Models are stored in `/Volumes/M-Drive/Coding/ava/models/`:

```
models/
‚îú‚îÄ‚îÄ original/          # FP32 unquantized models
‚îÇ   ‚îú‚îÄ‚îÄ AVA-ONX-384-BASE.onnx (86 MB)
‚îÇ   ‚îî‚îÄ‚îÄ AVA-ONX-384-MULTI.onnx (449 MB)
‚îî‚îÄ‚îÄ quantized/         # INT8 quantized models
    ‚îú‚îÄ‚îÄ AVA-ONX-384-BASE-INT8.onnx (22 MB) ‚Üê Bundled in APK
    ‚îî‚îÄ‚îÄ AVA-ONX-384-MULTI-INT8.onnx (113 MB) ‚Üê Available for download
```

**Files Modified:**
- `apps/ava-standalone/src/main/assets/models/AVA-ONX-384-BASE-INT8.onnx` - Bundled model (NEW)
- `ONNXEmbeddingProvider.android.kt` - Updated loading priority (assets first)
- `SettingsViewModel.kt` - Language detection and recommendations
- `SettingsScreen.kt` - Language recommendation banner UI
- `ModelDownloadManager.kt` - Updated model registry

**Testing:**

```kotlin
@Test
fun testBundledModelLoads() = runTest {
    val provider = ONNXEmbeddingProvider(context, modelId = "AVA-ONX-384-BASE-INT8")

    // Should load instantly from assets
    val isAvailable = provider.isAvailable()
    assertTrue(isAvailable)

    // Should generate embeddings immediately
    val result = provider.embed("test")
    assertTrue(result.isSuccess)
}

@Test
fun testLanguageDetection() {
    val viewModel = SettingsViewModel(context)

    // Mock device language
    Locale.setDefault(Locale("es")) // Spanish

    val recommended = viewModel.getRecommendedModelForLanguage()
    assertEquals("AVA-ONX-384-MULTI-INT8", recommended)

    val shouldSuggest = viewModel.shouldSuggestMultilingualDownload()
    assertTrue(shouldSuggest)
}
```

**See Also:**
- Section 28.6.4: Model Quantization
- Section 28.7.5: Model Selection via Settings UI
- `docs/MODEL-QUANTIZATION-GUIDE.md` - Quantization instructions
- `scripts/required/quantize-models.py` - Quantization tool

---

## 28.8 Performance Benchmarks

### Search Performance

| Chunks  | Linear (3.1) | Clustered (3.2) | Speedup | Status |
|---------|--------------|-----------------|---------|--------|
| 1,000   | 5ms          | 5ms             | 1x      | ‚úÖ     |
| 10,000  | 50ms         | 15ms            | 3.3x    | ‚úÖ     |
| 100,000 | 500ms        | 25ms            | 20x     | ‚úÖ     |
| 200,000 | 1,000ms      | 25ms            | **40x** | ‚úÖ     |

### Storage Requirements

| Chunks  | Total Size | Per Chunk | Cluster Overhead |
|---------|------------|-----------|------------------|
| 10,000  | 22 MB      | 2.2 KB    | 410 KB (1.8%)    |
| 50,000  | 110 MB     | 2.2 KB    | 410 KB (0.4%)    |
| 100,000 | 220 MB     | 2.2 KB    | 410 KB (0.2%)    |
| 200,000 | 440 MB     | 2.2 KB    | 410 KB (0.1%)    |

### Indexing Performance

**Sequential Processing (original):**
| Operation        | 10k chunks | 100k chunks | 200k chunks |
|------------------|------------|-------------|-------------|
| PDF parsing      | ~5 min     | ~50 min     | ~100 min    |
| Chunking         | ~10 sec    | ~100 sec    | ~200 sec    |
| Embedding gen    | ~8 min     | ~80 min     | ~160 min    |
| **Total**        | **~13 min**| **~130 min**| **~260 min**|
| Cluster build    | 5 sec      | 30 sec      | 60 sec      |

**Parallel Processing (NEW - 50% faster!):**
| Operation        | 10k chunks | 100k chunks | 200k chunks |
|------------------|------------|-------------|-------------|
| PDF parsing      | ~5 min     | ~50 min     | ~100 min    |
| Parallel pipeline| ~3 min     | ~30 min     | ~60 min     |
| **Total**        | **~8 min** | **~80 min** | **~160 min**|
| Cluster build    | 5 sec      | 30 sec      | 60 sec      |
| **Speedup**      | **38%**    | **38%**     | **38%**     |

**Document Format Performance (1000-page document):**
| Format | Parsing Speed | Total Time (parallel) | Notes |
|--------|---------------|----------------------|-------|
| **DOCX** | 10-20 pages/sec | **3-4 min** | 5-10x faster than PDF |
| HTML (local) | 20-50 pages/sec | **2-3 min** | Very fast, clean parsing |
| HTML (URL) | 20-50 pages/sec | **3-5 min** | Network latency added |
| TXT | Instant | **2-3 min** | Limited by chunking/embedding |
| Markdown | Instant | **2-3 min** | Limited by chunking/embedding |
| RTF | 5-10 pages/sec | **5-7 min** | Slower than DOCX |
| **PDF** | 2 pages/sec | **4.5-5.5 min** | Slowest but most common |

### Memory Usage

| Component        | Memory Usage |
|------------------|--------------|
| ONNX Model       | ~120 MB      |
| Room Database    | ~50 MB       |
| Cluster Cache    | ~5 MB        |
| **Total Active** | **~175 MB**  |

---

## 28.9 Document Management UI

### Overview

The RAG system includes a comprehensive Material 3-based UI with adaptive layouts for portrait and landscape orientations. The UI features gradient styling matching modern web standards and implements responsive design patterns for optimal user experience across device sizes.

### Screens

#### 1. Document Management Screen

**Purpose:** CRUD operations for document library

**Features:**
- Add documents via file picker or URL
- Grid/List adaptive layout (landscape: 2-3 columns, portrait: single column)
- Document status indicators (PENDING, PROCESSING, INDEXED, FAILED, OUTDATED, DELETED)
- Processing progress tracking
- Delete confirmation dialogs
- Document metadata display (file type, chunk count, creation date)

**Location:** `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/ui/DocumentManagementScreen.kt`

**Adaptive Layout:**
```kotlin
val windowSizeClass = rememberWindowSizeClass()

if (windowSizeClass.isLandscape && windowSizeClass.isMediumOrExpandedWidth) {
    // LANDSCAPE: Grid layout (2-3 columns)
    DocumentGrid(
        documents = documents,
        columns = if (windowSizeClass.isExpandedWidth) 3 else 2
    )
} else {
    // PORTRAIT: List layout
    LazyColumn { /* ... */ }
}
```

#### 2. RAG Chat Screen

**Purpose:** Conversational interface with RAG-enhanced responses

**Features:**
- Streaming chat with LLM (token-by-token display)
- Source citations for each response
- Two-pane landscape layout (35% sources sidebar + 65% chat)
- Animated message bubbles with slide-in effects
- Conversation history
- "No context" detection and fallback

**Location:** `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/ui/RAGChatScreen.kt`

**Two-Pane Layout:**
```kotlin
if (windowSizeClass.isLandscape && windowSizeClass.isMediumOrExpandedWidth) {
    Row {
        // LEFT: Sources Sidebar (35%)
        SourcesSidebar(
            sources = allSources,
            modifier = Modifier.weight(0.35f)
        )

        // RIGHT: Chat (65%)
        ChatPane(
            modifier = Modifier.weight(0.65f),
            showSourcesInMessages = false
        )
    }
} else {
    // PORTRAIT: Single column with inline sources
    ChatPane(showSourcesInMessages = true)
}
```

#### 3. RAG Search Screen

**Purpose:** Direct document search without LLM

**Features:**
- Real-time search with query preview
- Relevance scoring display
- Chunk content snippets
- Source highlighting
- Page number references
- Document filtering

**Location:** `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/ui/RAGSearchScreen.kt`

### Adaptive Layout System

#### WindowSizeUtils.kt

**Purpose:** Orientation and screen size detection

**Components:**
```kotlin
enum class WindowSize {
    COMPACT,  // Phone portrait (<600dp)
    MEDIUM,   // Phone landscape, small tablet (600-840dp)
    EXPANDED  // Large tablet, foldable (>840dp)
}

enum class Orientation {
    PORTRAIT,
    LANDSCAPE
}

data class WindowSizeClass(
    val widthSize: WindowSize,
    val heightSize: WindowSize,
    val orientation: Orientation
) {
    val isLandscape: Boolean
    val isMediumOrExpandedWidth: Boolean
}

@Composable
fun rememberWindowSizeClass(): WindowSizeClass
```

**Location:** `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/ui/WindowSizeUtils.kt`

**Breakpoints:**
- Compact: width < 600dp
- Medium: 600dp ‚â§ width < 840dp
- Expanded: width ‚â• 840dp

### Gradient Styling

#### GradientUtils.kt

**Purpose:** Consistent gradient styling matching HTML demo

**Colors:**
- Start: `#6366F1` (Indigo 500)
- End: `#8B5CF6` (Purple 500)

**Usage:**
```kotlin
// Apply gradient background
Modifier.gradientBackground()

// Gradient top bar
TopAppBar(
    title = { Text("Title", color = Color.White) },
    colors = TopAppBarDefaults.topAppBarColors(
        containerColor = Color.Transparent
    ),
    modifier = Modifier.gradientBackground()
)

// Gradient FAB
FloatingActionButton(
    onClick = { /* ... */ },
    modifier = Modifier.gradientBackground(),
    containerColor = Color.Transparent
) {
    Icon(Icons.Default.Add, contentDescription = "Add", tint = Color.White)
}
```

**Location:** `Universal/AVA/Features/RAG/src/androidMain/kotlin/com/augmentalis/ava/features/rag/ui/GradientUtils.kt`

### Animations

#### Message Slide-In Animation

**Specs:**
```kotlin
val MessageSlideInSpec = spring<IntOffset>(
    dampingRatio = Spring.DampingRatioMediumBouncy,
    stiffness = Spring.StiffnessLow
)

val FadeInSpec = tween<Float>(
    durationMillis = 300,
    easing = FastOutSlowInEasing
)
```

**Usage:**
```kotlin
AnimatedVisibility(
    visible = visible,
    enter = slideInVertically(
        initialOffsetY = { it / 4 },
        animationSpec = MessageSlideInSpec
    ) + fadeIn(animationSpec = FadeInSpec)
) {
    // Message content
}
```

### ViewModels

#### DocumentManagementViewModel

**Responsibilities:**
- Document CRUD operations
- File/URL processing
- Progress tracking
- Status message management
- Cluster rebuild orchestration

**Key Methods:**
```kotlin
fun addDocument(filePath: String, title: String? = null)
fun addDocumentFromUrl(url: String, title: String? = null)
fun deleteDocument(documentId: String)
fun rebuildClusters()
fun checkAndRebuildClusters()
```

#### RAGChatViewModel

**Responsibilities:**
- Chat message management
- Streaming response handling
- Source collection
- Conversation history
- Error handling

**Key Methods:**
```kotlin
fun sendMessage(question: String)
fun clearChat()
private fun convertToMessageHistory(): List<Message>
```

### Design Decisions

#### ADR: Adaptive Landscape UI

**Context:**
- Users requested proper landscape optimization
- HTML demo had gradient styling not present in app
- Material 3 basic design was too plain
- Horizontal space was underutilized

**Decision:**
- Implement WindowSizeClass-based adaptive layouts
- Two-pane layout for landscape chat (sources sidebar + messages)
- Grid layout for landscape documents (2-3 columns)
- Apply gradient styling (#6366f1 ‚Üí #8b5cf6)
- Add physics-based animations

**Benefits:**
- ‚úÖ Better UX on tablets and landscape phones
- ‚úÖ Proper horizontal space utilization
- ‚úÖ Matches modern web design aesthetics
- ‚úÖ Smooth, polished animations
- ‚úÖ Clear visual hierarchy

**Trade-offs:**
- ‚ö†Ô∏è Android-only (iOS/Desktop need separate implementations)
- ‚ö†Ô∏è Slightly increased complexity
- ‚ö†Ô∏è Additional 2 files (WindowSizeUtils, GradientUtils)

#### ADR: Two-Pane vs Tab Navigation

**Considered Alternatives:**
1. **Tabs for sources** - Rejected (requires switching, breaks flow)
2. **Bottom sheet for sources** - Rejected (obscures chat, requires manual toggle)
3. **Expandable inline sources** - Rejected (vertical space inefficient in landscape)
4. **Two-pane layout** - ‚úÖ Selected

**Rationale:**
- Persistent visibility of sources while chatting
- Efficient use of horizontal space
- No manual toggling required
- Aligns with tablet design patterns (e.g., Gmail, Files)

### Platform Support

| Feature | Android | iOS | Desktop |
|---------|---------|-----|---------|
| Document Management Screen | ‚úÖ | ‚ùå | ‚ùå |
| RAG Chat Screen | ‚úÖ | ‚ùå | ‚ùå |
| RAG Search Screen | ‚úÖ | ‚ùå | ‚ùå |
| Adaptive Layouts | ‚úÖ | ‚ùå | ‚ùå |
| Gradient Styling | ‚úÖ | ‚ùå | ‚ùå |
| Animations | ‚úÖ | ‚ùå | ‚ùå |

**Note:** iOS and Desktop platforms have placeholder implementations in Phase 2 TODOs.

### Future Enhancements

**Phase 3.3:**
- Dark mode support with gradient variations
- Haptic feedback for document operations
- Drag-and-drop document upload
- Multi-select for batch operations
- Export chat transcripts

**Phase 4:**
- Voice input for chat
- Image document preview
- Advanced filters (date range, file type, status)
- Document tagging system
- Favorites/bookmarks

---

## 28.10 Future Roadmap

### Phase 3.3: Cache & Optimization (Next)

**LRU Hot Cache:**
- Cache 10k most recent chunks in memory
- 4MB RAM footprint
- <5ms search for hot results

**Automatic Rebuild:**
- Trigger rebuild when chunk count increases >20%
- Background rebuild to avoid UI blocking
- Quality monitoring and alerts

**Query Caching:**
- Cache search results for common queries
- TTL-based expiration
- Cache hit metrics

### Phase 4: MLC-LLM Integration

**Gemma-2b-it Integration:**
- MLC-LLM Android integration
- RAG context assembly (top 3-5 chunks)
- Streaming response generation
- Token-by-token display

**Chat Interface:**
```kotlin
fun askQuestion(question: String): Flow<String> {
    // 1. Search for relevant chunks
    val searchResults = repository.search(
        SearchQuery(query = question, maxResults = 5)
    )

    // 2. Assemble context
    val context = searchResults.results.joinToString("\n\n") {
        "Source: ${it.document.title}\n${it.chunk.content}"
    }

    // 3. Generate response with LLM
    val prompt = """
        Based on the following information:

        $context

        Answer this question: $question
    """.trimIndent()

    return mlcLLM.generateStream(prompt)
}
```

### Future Enhancements

**Int8 Quantization:**
- 75% space savings (392 bytes vs 1536 bytes per embedding)
- 3% accuracy loss
- Already supported in schema

**‚úÖ COMPLETED - Additional Formats:**
- ‚úÖ DOCX (Apache POI) - **DONE**
- ‚úÖ TXT (native) - **DONE**
- ‚úÖ MD (native) - **DONE**
- ‚úÖ HTML (Jsoup) - **DONE**
- ‚úÖ RTF (RTFEditorKit) - **DONE**
- ‚è∏Ô∏è XLSX, PPTX (Apache POI)
- ‚è∏Ô∏è EPUB (Jsoup)
- ‚è∏Ô∏è Code files (syntax-aware chunking)

**‚úÖ PARTIALLY COMPLETED - RAG+LLM Integration:**
- ‚úÖ RAGChatEngine created - **DONE**
- ‚úÖ LLMProvider interface - **DONE**
- ‚úÖ Context assembly - **DONE**
- ‚úÖ Source citations - **DONE**
- ‚è∏Ô∏è MLC-LLM implementation (next)

**Multi-modal Embeddings:**
- Text + image embeddings (CLIP)
- Audio transcription + embedding
- Video frame analysis

**Hybrid Search:**
- Combine keyword search (FTS5) with semantic search
- Boost exact matches
- Filter by metadata

---

## Summary

**Chapter 28 Key Takeaways:**

1. **RAG enables instant document search** for field workers
2. **Offline-first architecture** with on-device processing
3. **40x performance improvement** through k-means clustering
4. **Production-ready** at 80% completion (Phases 1-3.2)
5. **Clean architecture** enables cross-platform expansion
6. **Privacy-first** with no cloud dependencies

**Current Status:** ‚úÖ **Operational and Production-Ready**

**Next Steps:** Phase 3.3 (LRU cache) ‚Üí Phase 4 (MLC-LLM integration)

---

**Related Documentation:**
- Quick Start Guide: `docs/RAG-Quick-Start-Guide.md`
- Phase 3.1 Complete: `docs/active/RAG-Phase3.1-Complete-251105.md`
- Phase 3.2 Complete: `docs/active/RAG-Phase3.2-Complete-251105.md`
- Status Report: `docs/active/RAG-Status-251105.md`
- Model Setup: `docs/MODEL-SETUP.md`
- LLM Setup: `docs/LLM-SETUP.md`
- **Chapter 73: Production Readiness & Security** - Complete encryption implementation details

---

**Updated:** 2025-12-06 (added encryption layer architecture and security features)
